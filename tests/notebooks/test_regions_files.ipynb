{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zarr\n",
    "from pathlib import Path\n",
    "from seqdata import Table, FlatFASTA, GenomeFASTA, BigWig, BAM\n",
    "import seqdata as sd\n",
    "import xarray as xr\n",
    "import pysam\n",
    "import random\n",
    "import pickle\n",
    "import pyBigWig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a temporary directory for the output\n",
    "os.makedirs(Path(sd.__file__).resolve().parent.parent / 'tests' / 'data' / 'tmp', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get infiles\n",
    "variable_fasta_in = Path(sd.__file__).resolve().parent.parent / 'tests' / 'data' / 'variable.fa'\n",
    "variable_bed_in = Path(sd.__file__).resolve().parent.parent / 'tests' / 'data' / 'variable.bed'\n",
    "fixed_bed_in = Path(sd.__file__).resolve().parent.parent / 'tests' / 'data' / 'fixed.bed'\n",
    "out = Path(sd.__file__).resolve().parent.parent / 'tests' / 'data' / 'tmp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `GenomeFasta`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data with Python as true representation\n",
    "def read_fasta(file_path):\n",
    "    sequences = {}\n",
    "    with open(file_path, 'r') as file:\n",
    "        sequence_id = None\n",
    "        sequence_lines = []\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\">\"):\n",
    "                if sequence_id:\n",
    "                    sequences[sequence_id] = ''.join(sequence_lines)\n",
    "                sequence_id = line[1:]  # Remove the '>'\n",
    "                sequence_lines = []\n",
    "            else:\n",
    "                sequence_lines.append(line)\n",
    "        if sequence_id:\n",
    "            sequences[sequence_id] = ''.join(sequence_lines)\n",
    "    return sequences\n",
    "\n",
    "\n",
    "def test_GenomeFASTA(input_fasta, input_bed, temp_dir, batch_size=50, fixed_length=20, length_dim=\"_length\"):\n",
    "    \"\"\"\n",
    "    Tests the GenomeFASTA class for a single input FASTA file and BED coordinates.\n",
    "\n",
    "    Parameters:\n",
    "        input_fasta (str or Path): Path to the input FASTA file.\n",
    "        bed (list): List of tuples (chromosome, start, end) representing BED coordinates.\n",
    "        temp_dir (str or Path): Directory where temporary files will be stored.\n",
    "        batch_size (int): Batch size for the GenomeFASTA reader.\n",
    "        fixed_length (int): Fixed length for the sequences when writing to Zarr.\n",
    "        length_dim (str): Name of the length dimension in the Zarr output.\n",
    "\n",
    "    Raises:\n",
    "        AssertionError: If any test fails.\n",
    "    \"\"\"\n",
    "    temp_dir = Path(temp_dir)\n",
    "    temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    fasta_out = temp_dir / 'output.fasta.zarr'\n",
    "\n",
    "    bed = pd.read_csv(input_bed, sep=\"\\t\", header=None)\n",
    "    fasta_sequences = read_fasta(input_fasta)\n",
    "    if fixed_length:\n",
    "        midpoint = (bed[1] + bed[2]) // 2\n",
    "        bed[1] = midpoint - fixed_length // 2\n",
    "        bed[2] = midpoint + fixed_length // 2\n",
    "    true = [fasta_sequences[chrom][start:end] for chrom, start, end in bed.values]\n",
    "    bed[\"strand\"] = \"+\"\n",
    "\n",
    "    # Test instantiation of the GenomeFASTA reader class\n",
    "    genomefasta_reader = GenomeFASTA(\n",
    "        name=\"seq\",\n",
    "        fasta=input_fasta,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    assert isinstance(genomefasta_reader, GenomeFASTA), \"GenomeFASTA reader instantiation failed.\"\n",
    "\n",
    "    # Read in the data using the reader\n",
    "    iterator = genomefasta_reader._reader(\n",
    "        bed=bed,\n",
    "        f=pysam.FastaFile(input_fasta)\n",
    "    )\n",
    "    _read = [seq.decode('utf-8') for seq in iterator]\n",
    "    assert np.array_equal(_read, true), \"GenomeFASTA reader failed to read in the correct values.\"\n",
    "\n",
    "    # Test writing to Zarr\n",
    "    genomefasta_reader._write(\n",
    "        fasta_out,\n",
    "        bed=bed,\n",
    "        fixed_length=fixed_length,\n",
    "        sequence_dim=\"_sequence\",\n",
    "        length_dim=length_dim,\n",
    "        overwrite=True\n",
    "    )\n",
    "    zarr.consolidate_metadata(fasta_out)\n",
    "\n",
    "    # Test round-trip reading\n",
    "    data = sd.open_zarr(fasta_out)\n",
    "\n",
    "    # Verify length and sequence dimensions\n",
    "    if fixed_length:\n",
    "        assert data[\"seq\"].shape[1] == fixed_length, \"Length dimension is incorrect.\"\n",
    "    assert data[\"seq\"].shape[0] == len(bed), \"Sequence dimension is incorrect.\"\n",
    "\n",
    "    # Verify that the data is the same\n",
    "    if fixed_length:\n",
    "        seqs = [''.join(row.astype(str)) for row in data[\"seq\"].values]\n",
    "    else:\n",
    "        seqs = data[\"seq\"].values.astype(str)\n",
    "    print(seqs)\n",
    "    print(true)\n",
    "    assert np.array_equal(true, seqs), \"Sequences do not match.\"\n",
    "\n",
    "    # Clean up temporary files\n",
    "    for f in temp_dir.iterdir():\n",
    "        if f.is_dir():\n",
    "            os.system(f'rm -r {f}')\n",
    "        else:\n",
    "            f.unlink()\n",
    "\n",
    "    print(\"All tests passed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 74518.09it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 76858.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CGCAAGAACCCATGATCTATCACAG' 'GCAACCAGTTCAGACGTATAAA'\n",
      " 'AACATGGGGCcCATGTTAGTTTAGGTG' 'CAATGgAGCGAAGCGtCTaGG'\n",
      " 'GCTAGTGATCGCATCGGGCTGTC' 'AAGCCACGCACTCCCATAGTATGGTTGCG'\n",
      " 'CGACTCATACAACAGTACTT' 'TTCCACACATCGAATTCCTGTACATACTC'\n",
      " 'CGTGTCTTATTCGAGCTGCCAGTCT' 'ATAGTGGGAGTGAATCAATCCTGAAC'\n",
      " 'ACTCCAGCCGACTACTCTAGT' 'GCGCCCTATTCCTGTCAAGTACTA'\n",
      " 'TCTAATTGTTATCCGAAACGAGTAATG' 'TTACGTCACCATGCTGTTTCGG']\n",
      "['CGCAAGAACCCATGATCTATCACAG', 'GCAACCAGTTCAGACGTATAAA', 'AACATGGGGCcCATGTTAGTTTAGGTG', 'CAATGgAGCGAAGCGtCTaGG', 'GCTAGTGATCGCATCGGGCTGTC', 'AAGCCACGCACTCCCATAGTATGGTTGCG', 'CGACTCATACAACAGTACTT', 'TTCCACACATCGAATTCCTGTACATACTC', 'CGTGTCTTATTCGAGCTGCCAGTCT', 'ATAGTGGGAGTGAATCAATCCTGAAC', 'ACTCCAGCCGACTACTCTAGT', 'GCGCCCTATTCCTGTCAAGTACTA', 'TCTAATTGTTATCCGAAACGAGTAATG', 'TTACGTCACCATGCTGTTTCGG']\n",
      "All tests passed successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the GenomeFASTA class on variable length sequences\n",
    "test_GenomeFASTA(variable_fasta_in, variable_bed_in, out, batch_size=50, fixed_length=False, length_dim=\"_length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 95635.60it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 77060.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CAAGAACCCATGATCTATCA', 'CAACCAGTTCAGACGTATAA', 'ATGGGGCcCATGTTAGTTTA', 'CAATGgAGCGAAGCGtCTaG', 'CTAGTGATCGCATCGGGCTG', 'CACGCACTCCCATAGTATGG', 'CGACTCATACAACAGTACTT', 'ACACATCGAATTCCTGTACA', 'TGTCTTATTCGAGCTGCCAG', 'GTGGGAGTGAATCAATCCTG', 'ACTCCAGCCGACTACTCTAG', 'GCCCTATTCCTGTCAAGTAC', 'AATTGTTATCCGAAACGAGT', 'TACGTCACCATGCTGTTTCG']\n",
      "['CAAGAACCCATGATCTATCA', 'CAACCAGTTCAGACGTATAA', 'ATGGGGCcCATGTTAGTTTA', 'CAATGgAGCGAAGCGtCTaG', 'CTAGTGATCGCATCGGGCTG', 'CACGCACTCCCATAGTATGG', 'CGACTCATACAACAGTACTT', 'ACACATCGAATTCCTGTACA', 'TGTCTTATTCGAGCTGCCAG', 'GTGGGAGTGAATCAATCCTG', 'ACTCCAGCCGACTACTCTAG', 'GCCCTATTCCTGTCAAGTAC', 'AATTGTTATCCGAAACGAGT', 'TACGTCACCATGCTGTTTCG']\n",
      "All tests passed successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the GenomeFASTA class on variable length sequences\n",
    "test_GenomeFASTA(variable_fasta_in, variable_bed_in, out, batch_size=50, fixed_length=20, length_dim=\"_length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 74518.09it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 55240.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CGCAAGAACCCATGATCTAT', 'GCAACCAGTTCAGACGTATA', 'AACATGGGGCcCATGTTAGT', 'CAATGgAGCGAAGCGtCTaG', 'GCTAGTGATCGCATCGGGCT', 'AAGCCACGCACTCCCATAGT', 'CGACTCATACAACAGTACTT', 'TTCCACACATCGAATTCCTG', 'CGTGTCTTATTCGAGCTGCC', 'ATAGTGGGAGTGAATCAATC', 'ACTCCAGCCGACTACTCTAG', 'GCGCCCTATTCCTGTCAAGT', 'TCTAATTGTTATCCGAAACG', 'TTACGTCACCATGCTGTTTC']\n",
      "['CGCAAGAACCCATGATCTAT', 'GCAACCAGTTCAGACGTATA', 'AACATGGGGCcCATGTTAGT', 'CAATGgAGCGAAGCGtCTaG', 'GCTAGTGATCGCATCGGGCT', 'AAGCCACGCACTCCCATAGT', 'CGACTCATACAACAGTACTT', 'TTCCACACATCGAATTCCTG', 'CGTGTCTTATTCGAGCTGCC', 'ATAGTGGGAGTGAATCAATC', 'ACTCCAGCCGACTACTCTAG', 'GCGCCCTATTCCTGTCAAGT', 'TCTAATTGTTATCCGAAACG', 'TTACGTCACCATGCTGTTTC']\n",
      "All tests passed successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the GenomeFASTA class on fixed length sequences\n",
    "test_GenomeFASTA(variable_fasta_in, fixed_bed_in, out, batch_size=50, fixed_length=20, length_dim=\"_length\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `BAM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/simulated1.bam'),\n",
       " PosixPath('/cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/simulated2.bam'),\n",
       " PosixPath('/cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/simulated3.bam'),\n",
       " PosixPath('/cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/simulated4.bam'),\n",
       " PosixPath('/cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/simulated5.bam')]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of bams with simulated{1-5}.bam\n",
    "bams = [Path(sd.__file__).resolve().parent.parent / 'tests' / 'data' / f'simulated{i}.bam' for i in range(1, 6)]\n",
    "bams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in coverage\n",
    "path_coverage = Path(sd.__file__).resolve().parent.parent / 'tests' / 'data' / 'variable.bedcov.pkl'\n",
    "coverages = pickle.load(open(path_coverage, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1</td>\n",
       "      <td>23</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr1</td>\n",
       "      <td>65</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr2</td>\n",
       "      <td>54</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr2</td>\n",
       "      <td>127</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr3</td>\n",
       "      <td>33</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>chr3</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>chr4</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>chr4</td>\n",
       "      <td>55</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>chr5</td>\n",
       "      <td>139</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>chr5</td>\n",
       "      <td>248</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>chr6</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>chr6</td>\n",
       "      <td>68</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>chr7</td>\n",
       "      <td>72</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>chr7</td>\n",
       "      <td>157</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2\n",
       "0   chr1   23   43\n",
       "1   chr1   65   85\n",
       "2   chr2   54   74\n",
       "3   chr2  127  147\n",
       "4   chr3   33   53\n",
       "5   chr3   80  100\n",
       "6   chr4   13   33\n",
       "7   chr4   55   75\n",
       "8   chr5  139  159\n",
       "9   chr5  248  268\n",
       "10  chr6   20   40\n",
       "11  chr6   68   88\n",
       "12  chr7   72   92\n",
       "13  chr7  157  177"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the bed file\n",
    "bed = pd.read_csv(fixed_bed_in, sep=\"\\t\", header=None)\n",
    "bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region: chr1:23-48 -> chr1:23-43\n",
      "[2 2 2 2 1 1 2 1 1 2 2 2 3 3 3 3 2 2 2 1 1 2 1 1 1]\n",
      "Offsets: 0, -5\n",
      "Region: chr1:65-87 -> chr1:65-85\n",
      "[2 1 1 2 2 2 2 2 2 2 2 3 3 2 4 4 3 3 5 5 6 6]\n",
      "Offsets: 0, -2\n",
      "Region: chr2:54-81 -> chr2:54-74\n",
      "[1 1 1 1 2 3 2 3 3 3 4 5 5 5 4 3 3 2 3 4 3 2 3 3 3 4 4]\n",
      "Offsets: 0, -7\n",
      "Region: chr2:127-148 -> chr2:127-147\n",
      "[1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0]\n",
      "Offsets: 0, -1\n",
      "Region: chr3:33-56 -> chr3:33-53\n",
      "[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "Offsets: 0, -3\n",
      "Region: chr3:80-109 -> chr3:80-100\n",
      "[2 2 2 3 3 4 3 2 2 2 2 3 4 3 3 2 2 2 3 3 3 2 1 1 1 1 1 1 0]\n",
      "Offsets: 0, -9\n",
      "Region: chr4:13-33 -> chr4:13-33\n",
      "[3 4 4 4 4 5 5 3 3 3 3 3 6 6 6 5 6 5 5 5]\n",
      "Offsets: 0, 0\n",
      "Region: chr4:55-84 -> chr4:55-75\n",
      "[3 3 3 3 3 3 3 2 4 4 4 4 5 5 5 5 6 6 4 4 4 3 2 4 4 5 3 3 3]\n",
      "Offsets: 0, -9\n",
      "Region: chr5:139-164 -> chr5:139-159\n",
      "[0 0 1 1 1 1 1 1 2 3 3 3 2 2 2 2 2 4 3 2 2 2 4 5 6]\n",
      "Offsets: 0, -5\n",
      "Region: chr5:248-274 -> chr5:248-268\n",
      "[1 2 1 1 1 2 2 3 3 3 3 2 2 3 3 4 6 5 5 5 7 8 9 8 8 6]\n",
      "Offsets: 0, -6\n",
      "Region: chr6:20-41 -> chr6:20-40\n",
      "[4 3 3 3 3 2 2 2 2 2 2 3 3 5 5 7 6 6 7 7 6]\n",
      "Offsets: 0, -1\n",
      "Region: chr6:68-92 -> chr6:68-88\n",
      "[3 3 2 2 3 4 4 5 5 5 3 3 3 3 2 3 3 2 2 3 3 3 3 3]\n",
      "Offsets: 0, -4\n",
      "Region: chr7:72-99 -> chr7:72-92\n",
      "[0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 2 2 2 2 2 3 3 3]\n",
      "Offsets: 0, -7\n",
      "Region: chr7:157-179 -> chr7:157-177\n",
      "[1 1 1 2 2 3 3 4 3 3 3 3 5 5 6 5 5 4 5 5 5 5]\n",
      "Offsets: 0, -2\n",
      "Region: chr1:23-48 -> chr1:23-43\n",
      "[1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0]\n",
      "Offsets: 0, -5\n",
      "Region: chr1:65-87 -> chr1:65-85\n",
      "[1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 2 2 2 2 2 2 2]\n",
      "Offsets: 0, -2\n",
      "Region: chr2:54-81 -> chr2:54-74\n",
      "[2 2 1 2 2 2 3 4 4 4 3 3 3 2 2 3 2 1 2 2 2 3 3 3 3 2 2]\n",
      "Offsets: 0, -7\n",
      "Region: chr2:127-148 -> chr2:127-147\n",
      "[2 1 0 0 0 0 1 3 3 3 3 3 3 5 5 6 5 3 4 4 4]\n",
      "Offsets: 0, -1\n",
      "Region: chr3:33-56 -> chr3:33-53\n",
      "[1 2 2 2 3 4 4 4 4 4 4 3 3 3 3 3 4 5 5 6 6 6 6]\n",
      "Offsets: 0, -3\n",
      "Region: chr3:80-109 -> chr3:80-100\n",
      "[1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0]\n",
      "Offsets: 0, -9\n",
      "Region: chr4:13-33 -> chr4:13-33\n",
      "[2 3 3 3 2 1 4 4 4 5 6 5 5 5 5 5 3 3 3 2]\n",
      "Offsets: 0, 0\n",
      "Region: chr4:55-84 -> chr4:55-75\n",
      "[0 1 1 1 1 1 1 1 1 1 1 0 1 3 3 3 5 5 7 7 7 7 6 5 5 5 3 5 5]\n",
      "Offsets: 0, -9\n",
      "Region: chr5:139-164 -> chr5:139-159\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 2 2 2 2 3 3]\n",
      "Offsets: 0, -5\n",
      "Region: chr5:248-274 -> chr5:248-268\n",
      "[0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 2 4 4 4 4]\n",
      "Offsets: 0, -6\n",
      "Region: chr6:20-41 -> chr6:20-40\n",
      "[1 1 1 1 2 2 2 2 2 2 2 2 4 4 3 4 4 4 4 8 7]\n",
      "Offsets: 0, -1\n",
      "Region: chr6:68-92 -> chr6:68-88\n",
      "[0 0 0 1 1 1 1 2 2 2 2 2 2 1 1 1 1 0 1 1 1 1 2 2]\n",
      "Offsets: 0, -4\n",
      "Region: chr7:72-99 -> chr7:72-92\n",
      "[4 4 5 3 2 3 2 2 4 5 5 7 6 7 7 6 6 7 5 4 4 2 2 1 1 1 3]\n",
      "Offsets: 0, -7\n",
      "Region: chr7:157-179 -> chr7:157-177\n",
      "[2 2 2 2 3 4 3 4 3 3 3 4 4 5 4 3 3 2 2 3 4 3]\n",
      "Offsets: 0, -2\n",
      "Region: chr1:23-48 -> chr1:23-43\n",
      "[1 1 1 1 1 1 1 1 0 0 0 0 0 2 2 2 2 2 2 2 3 3 3 1 2]\n",
      "Offsets: 0, -5\n",
      "Region: chr1:65-87 -> chr1:65-85\n",
      "[4 4 5 4 4 5 6 5 5 5 5 5 4 4 4 4 3 4 4 4 7 8]\n",
      "Offsets: 0, -2\n",
      "Region: chr2:54-81 -> chr2:54-74\n",
      "[1 1 1 1 1 2 2 2 2 1 1 1 1 1 3 2 2 2 2 2 2 2 2 3 1 1 1]\n",
      "Offsets: 0, -7\n",
      "Region: chr2:127-148 -> chr2:127-147\n",
      "[2 2 1 1 1 1 1 2 2 2 1 1 1 1 1 2 2 1 1 1 1]\n",
      "Offsets: 0, -1\n",
      "Region: chr3:33-56 -> chr3:33-53\n",
      "[1 0 0 0 0 0 1 2 2 2 2 2 2 2 3 3 2 2 2 2 3 3 4]\n",
      "Offsets: 0, -3\n",
      "Region: chr3:80-109 -> chr3:80-100\n",
      "[1 1 1 1 1 1 1 1 1 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Offsets: 0, -9\n",
      "Region: chr4:13-33 -> chr4:13-33\n",
      "[5 4 4 3 2 3 3 3 3 4 4 5 5 6 6 5 4 4 3 2]\n",
      "Offsets: 0, 0\n",
      "Region: chr4:55-84 -> chr4:55-75\n",
      "[0 0 0 0 0 0 0 0 0 1 1 1 2 2 3 3 4 4 4 3 3 3 3 3 4 4 4 5 5]\n",
      "Offsets: 0, -9\n",
      "Region: chr5:139-164 -> chr5:139-159\n",
      "[3 2 2 3 4 4 4 5 5 5 5 7 7 6 5 6 6 5 6 7 6 4 5 5 6]\n",
      "Offsets: 0, -5\n",
      "Region: chr5:248-274 -> chr5:248-268\n",
      "[4 4 4 4 2 1 1 1 2 4 5 5 7 7 7 7 8 7 6 4 5 5 4 5 5 5]\n",
      "Offsets: 0, -6\n",
      "Region: chr6:20-41 -> chr6:20-40\n",
      "[1 0 0 0 0 0 1 1 2 2 2 2 2 2 2 2 1 2 1 1 1]\n",
      "Offsets: 0, -1\n",
      "Region: chr6:68-92 -> chr6:68-88\n",
      "[3 3 1 1 1 1 1 3 3 3 3 3 4 4 4 4 4 1 1 1 1 1 1 1]\n",
      "Offsets: 0, -4\n",
      "Region: chr7:72-99 -> chr7:72-92\n",
      "[2 2 1 1 0 1 1 2 2 4 4 4 4 4 4 3 3 2 2 0 0 0 0 0 1 1 1]\n",
      "Offsets: 0, -7\n",
      "Region: chr7:157-179 -> chr7:157-177\n",
      "[1 1 1 1 1 1 1 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1]\n",
      "Offsets: 0, -2\n",
      "Region: chr1:23-48 -> chr1:23-43\n",
      "[1 1 1 1 1 1 0 0 0 1 1 2 2 2 2 3 3 3 3 2 3 2 2 2 3]\n",
      "Offsets: 0, -5\n",
      "Region: chr1:65-87 -> chr1:65-85\n",
      "[4 3 3 2 1 0 1 1 1 2 3 3 3 3 3 3 2 2 2 1 0 0]\n",
      "Offsets: 0, -2\n",
      "Region: chr2:54-81 -> chr2:54-74\n",
      "[1 1 1 0 1 1 1 1 3 3 3 3 3 4 3 3 3 3 1 2 2 2 2 3 4 5 5]\n",
      "Offsets: 0, -7\n",
      "Region: chr2:127-148 -> chr2:127-147\n",
      "[2 2 2 3 3 3 4 4 4 4 4 4 4 3 3 3 2 2 3 3 3]\n",
      "Offsets: 0, -1\n",
      "Region: chr3:33-56 -> chr3:33-53\n",
      "[1 1 2 2 2 2 2 3 4 5 4 4 3 3 3 4 4 4 3 2 2 2 3]\n",
      "Offsets: 0, -3\n",
      "Region: chr3:80-109 -> chr3:80-100\n",
      "[2 2 2 2 2 2 2 3 3 3 2 2 1 1 1 2 2 2 2 2 2 2 2 2 2 1 1 0 0]\n",
      "Offsets: 0, -9\n",
      "Region: chr4:13-33 -> chr4:13-33\n",
      "[5 5 4 4 4 4 4 3 2 2 3 3 5 6 6 5 6 5 5 6]\n",
      "Offsets: 0, 0\n",
      "Region: chr4:55-84 -> chr4:55-75\n",
      "[1 1 1 1 1 2 2 2 3 5 5 5 4 4 4 3 4 6 5 3 3 3 4 5 7 7 7 5 5]\n",
      "Offsets: 0, -9\n",
      "Region: chr5:139-164 -> chr5:139-159\n",
      "[4 4 2 2 3 2 3 5 6 7 7 7 7 7 6 7 6 5 5 5 4 5 5 6 7]\n",
      "Offsets: 0, -5\n",
      "Region: chr5:248-274 -> chr5:248-268\n",
      "[2 2 3 3 2 2 2 3 3 3 3 4 3 3 4 4 4 4 4 3 4 3 4 5 5 5]\n",
      "Offsets: 0, -6\n",
      "Region: chr6:20-41 -> chr6:20-40\n",
      "[0 1 2 2 2 2 2 3 3 3 4 3 3 3 3 3 4 5 6 6 5]\n",
      "Offsets: 0, -1\n",
      "Region: chr6:68-92 -> chr6:68-88\n",
      "[3 3 4 3 4 5 4 4 5 5 5 6 6 6 5 4 4 4 3 4 5 4 4 4]\n",
      "Offsets: 0, -4\n",
      "Region: chr7:72-99 -> chr7:72-92\n",
      "[1 0 0 0 0 0 1 1 2 2 2 2 2 2 2 2 1 1 0 1 1 1 1 2 2 2 2]\n",
      "Offsets: 0, -7\n",
      "Region: chr7:157-179 -> chr7:157-177\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]\n",
      "Offsets: 0, -2\n",
      "Region: chr1:23-48 -> chr1:23-43\n",
      "[4 3 3 2 2 3 5 4 5 5 4 4 6 7 7 7 5 5 4 5 6 7 5 5 5]\n",
      "Offsets: 0, -5\n",
      "Region: chr1:65-87 -> chr1:65-85\n",
      "[3 3 2 3 3 6 4 5 5 5 5 6 6 5 6 3 4 3 4 4 6 5]\n",
      "Offsets: 0, -2\n",
      "Region: chr2:54-81 -> chr2:54-74\n",
      "[2 2 2 2 1 1 1 1 1 2 1 1 1 1 2 3 3 3 3 2 2 2 2 2 1 0 0]\n",
      "Offsets: 0, -7\n",
      "Region: chr2:127-148 -> chr2:127-147\n",
      "[2 2 2 2 2 2 2 2 0 0 0 0 0 2 2 2 2 2 3 3 3]\n",
      "Offsets: 0, -1\n",
      "Region: chr3:33-56 -> chr3:33-53\n",
      "[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "Offsets: 0, -3\n",
      "Region: chr3:80-109 -> chr3:80-100\n",
      "[2 2 2 2 2 1 0 0 0 0 1 2 2 2 2 2 2 2 2 2 1 0 0 0 0 0 0 0 0]\n",
      "Offsets: 0, -9\n",
      "Region: chr4:13-33 -> chr4:13-33\n",
      "[2 2 2 2 2 2 2 2 2 1 0 0 0 0 1 2 2 2 2 2]\n",
      "Offsets: 0, 0\n",
      "Region: chr4:55-84 -> chr4:55-75\n",
      "[0 1 2 3 3 3 3 3 3 3 3 2 1 0 0 0 1 2 3 3 3 3 3 3 4 4 3 2 1]\n",
      "Offsets: 0, -9\n",
      "Region: chr5:139-164 -> chr5:139-159\n",
      "[3 2 2 2 2 2 4 4 4 4 3 3 3 4 5 6 5 5 5 4 4 5 5 4 4]\n",
      "Offsets: 0, -5\n",
      "Region: chr5:248-274 -> chr5:248-268\n",
      "[0 0 0 0 0 0 0 0 0 1 1 2 2 2 2 2 2 2 2 1 1 0 0 0 1 1]\n",
      "Offsets: 0, -6\n",
      "Region: chr6:20-41 -> chr6:20-40\n",
      "[1 2 2 2 1 2 2 2 2 5 6 6 7 7 7 6 7 7 7 4 5]\n",
      "Offsets: 0, -1\n",
      "Region: chr6:68-92 -> chr6:68-88\n",
      "[3 2 2 1 1 1 4 4 5 5 5 4 4 4 4 4 2 2 1 1 1 2 2 2]\n",
      "Offsets: 0, -4\n",
      "Region: chr7:72-99 -> chr7:72-92\n",
      "[1 2 1 1 1 2 2 3 3 3 3 2 2 2 3 2 3 2 3 3 3 3 3 3 2 2 1]\n",
      "Offsets: 0, -7\n",
      "Region: chr7:157-179 -> chr7:157-177\n",
      "[2 2 3 3 3 4 4 3 3 3 3 4 6 6 6 5 4 5 5 5 6 6]\n",
      "Offsets: 0, -2\n"
     ]
    }
   ],
   "source": [
    "# Subset the coverage to the bed file coordinates\n",
    "new_cov = {}\n",
    "# for each bam file\n",
    "for bam in bams:\n",
    "    bam_name = bam.name\n",
    "    new_cov[bam_name] = {}\n",
    "    for i, (region, coverage) in enumerate(coverages[bam_name].items()):\n",
    "        coverage_interval = region.split(\":\")[1]\n",
    "        coverage_start, coverage_end = map(int, coverage_interval.split(\"-\"))\n",
    "        start_offset = coverage_start - bed[1].values[i]\n",
    "        end_offset = bed[2].values[i] - coverage_end\n",
    "        new_region = f\"{bed[0].values[i]}:{bed[1].values[i]}-{bed[2].values[i]}\"\n",
    "        print(f\"Region: {region} -> {new_region}\")\n",
    "        print(coverage)\n",
    "        print(f\"Offsets: {start_offset}, {end_offset}\")\n",
    "        if end_offset == 0:\n",
    "            new_cov[bam_name][new_region] = coverage[start_offset:]\n",
    "        else:\n",
    "            new_cov[bam_name][new_region] = coverage[start_offset:end_offset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_BAM(bam_files, bed_file, coverages, temp_dir, batch_size=50, sequence_dim=\"_sequence\"):\n",
    "    \"\"\"\n",
    "    Tests the BAM class for one or more input BAM files and their coverage.\n",
    "\n",
    "    Parameters:\n",
    "        bam_files (list): List of paths to BAM files.\n",
    "        bed_file (str or Path): Path to the BED file.\n",
    "        coverage_file (str or Path): Path to the pickled coverage file.\n",
    "        temp_dir (str or Path): Directory where temporary files will be stored.\n",
    "        batch_size (int): Batch size for the BAM reader.\n",
    "        sequence_dim (str): Name of the sequence dimension in the Zarr output.\n",
    "\n",
    "    Raises:\n",
    "        AssertionError: If any test fails.\n",
    "    \"\"\"\n",
    "    temp_dir = Path(temp_dir)\n",
    "    temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    bam_out = temp_dir / 'output.bam.zarr'\n",
    "\n",
    "    # Test instantiation of the BAM reader class\n",
    "    bam_reader = BAM(\n",
    "        name=\"cov\",\n",
    "        bams=bam_files,\n",
    "        samples=[bam.name for bam in bam_files],\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    assert isinstance(bam_reader, BAM), \"BAM reader instantiation failed.\"\n",
    "\n",
    "    # Read in the BED file\n",
    "    bed = pd.read_csv(bed_file, sep=\"\\t\", header=None)\n",
    "\n",
    "    # Verify each BAM file individually\n",
    "    for bam_file in bam_files:\n",
    "        print(f\"Testing {bam_file}\")\n",
    "        bam_name = bam_file.name\n",
    "        iterator = bam_reader._reader(bed=bed, f=pysam.AlignmentFile(bam_file))\n",
    "        _read = [list(seq) for seq in iterator]\n",
    "\n",
    "        # Verify that the data matches the expected coverage\n",
    "        for i, (region, coverage) in enumerate(coverages[bam_name].items()):\n",
    "            print(f\"Region {region}: {list(_read[i])}, {coverage}\")\n",
    "            assert np.array_equal(coverage, _read[i]), f\"Region {region} in {bam_name} does not match.\"\n",
    "\n",
    "    # Test writing to Zarr\n",
    "    bed[\"strand\"] = \"+\"\n",
    "    bam_reader._write(\n",
    "        bam_out,\n",
    "        bed=bed,\n",
    "        fixed_length=False,\n",
    "        sequence_dim=sequence_dim,\n",
    "        overwrite=True\n",
    "    )\n",
    "    zarr.consolidate_metadata(bam_out)\n",
    "\n",
    "    # Test round-trip reading\n",
    "    data = sd.open_zarr(bam_out)\n",
    "\n",
    "    # Verify that the data matches the expected coverage for all regions\n",
    "    for file_index, bam_file in enumerate(bam_files):\n",
    "        print(f\"Testing {bam_file}\")\n",
    "        bam_name = bam_file.name\n",
    "        for region_index, (region, coverage) in enumerate(coverages[bam_name].items()):\n",
    "            print(data['cov'][region_index].shape)\n",
    "            #print(f\"Region {region}: {list(data['cov'].values[:, i])}, {coverage}\")\n",
    "            assert np.array_equal(coverage, data[\"cov\"].values[region_index, file_index]), f\"Region {region} in {bam_name} does not match.\"\n",
    "\n",
    "    # Clean up temporary files\n",
    "    for f in temp_dir.iterdir():\n",
    "        if f.is_dir():\n",
    "            os.system(f'rm -r {f}')\n",
    "        else:\n",
    "            f.unlink()\n",
    "\n",
    "    print(\"All tests passed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing /cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/simulated1.bam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 12868.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region chr1:23-43: [2, 2, 2, 2, 1, 1, 2, 1, 1, 2, 2, 2, 3, 3, 3, 3, 2, 2, 2, 1], [2 2 2 2 1 1 2 1 1 2 2 2 3 3 3 3 2 2 2 1]\n",
      "Region chr1:65-85: [2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 4, 4, 3, 3, 5, 5], [2 1 1 2 2 2 2 2 2 2 2 3 3 2 4 4 3 3 5 5]\n",
      "Region chr2:54-74: [1, 1, 1, 1, 2, 3, 2, 3, 3, 3, 4, 5, 5, 5, 4, 3, 3, 2, 3, 4], [1 1 1 1 2 3 2 3 3 3 4 5 5 5 4 3 3 2 3 4]\n",
      "Region chr2:127-147: [1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0], [1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0]\n",
      "Region chr3:33-53: [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0], [0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0]\n",
      "Region chr3:80-100: [2, 2, 2, 3, 3, 4, 3, 2, 2, 2, 2, 3, 4, 3, 3, 2, 2, 2, 3, 3], [2 2 2 3 3 4 3 2 2 2 2 3 4 3 3 2 2 2 3 3]\n",
      "Region chr4:13-33: [3, 4, 4, 4, 4, 5, 5, 3, 3, 3, 3, 3, 6, 6, 6, 5, 6, 5, 5, 5], [3 4 4 4 4 5 5 3 3 3 3 3 6 6 6 5 6 5 5 5]\n",
      "Region chr4:55-75: [3, 3, 3, 3, 3, 3, 3, 2, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 4, 4], [3 3 3 3 3 3 3 2 4 4 4 4 5 5 5 5 6 6 4 4]\n",
      "Region chr5:139-159: [0, 0, 1, 1, 1, 1, 1, 1, 2, 3, 3, 3, 2, 2, 2, 2, 2, 4, 3, 2], [0 0 1 1 1 1 1 1 2 3 3 3 2 2 2 2 2 4 3 2]\n",
      "Region chr5:248-268: [1, 2, 1, 1, 1, 2, 2, 3, 3, 3, 3, 2, 2, 3, 3, 4, 6, 5, 5, 5], [1 2 1 1 1 2 2 3 3 3 3 2 2 3 3 4 6 5 5 5]\n",
      "Region chr6:20-40: [4, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 3, 3, 5, 5, 7, 6, 6, 7, 7], [4 3 3 3 3 2 2 2 2 2 2 3 3 5 5 7 6 6 7 7]\n",
      "Region chr6:68-88: [3, 3, 2, 2, 3, 4, 4, 5, 5, 5, 3, 3, 3, 3, 2, 3, 3, 2, 2, 3], [3 3 2 2 3 4 4 5 5 5 3 3 3 3 2 3 3 2 2 3]\n",
      "Region chr7:72-92: [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2], [0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 2]\n",
      "Region chr7:157-177: [1, 1, 1, 2, 2, 3, 3, 4, 3, 3, 3, 3, 5, 5, 6, 5, 5, 4, 5, 5], [1 1 1 2 2 3 3 4 3 3 3 3 5 5 6 5 5 4 5 5]\n",
      "Testing /cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/simulated2.bam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 8764.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region chr1:23-43: [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]\n",
      "Region chr1:65-85: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2], [1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 2 2 2 2 2]\n",
      "Region chr2:54-74: [2, 2, 1, 2, 2, 2, 3, 4, 4, 4, 3, 3, 3, 2, 2, 3, 2, 1, 2, 2], [2 2 1 2 2 2 3 4 4 4 3 3 3 2 2 3 2 1 2 2]\n",
      "Region chr2:127-147: [2, 1, 0, 0, 0, 0, 1, 3, 3, 3, 3, 3, 3, 5, 5, 6, 5, 3, 4, 4], [2 1 0 0 0 0 1 3 3 3 3 3 3 5 5 6 5 3 4 4]\n",
      "Region chr3:33-53: [1, 2, 2, 2, 3, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 4, 5, 5, 6], [1 2 2 2 3 4 4 4 4 4 4 3 3 3 3 3 4 5 5 6]\n",
      "Region chr3:80-100: [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]\n",
      "Region chr4:13-33: [2, 3, 3, 3, 2, 1, 4, 4, 4, 5, 6, 5, 5, 5, 5, 5, 3, 3, 3, 2], [2 3 3 3 2 1 4 4 4 5 6 5 5 5 5 5 3 3 3 2]\n",
      "Region chr4:55-75: [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 3, 3, 3, 5, 5, 7, 7], [0 1 1 1 1 1 1 1 1 1 1 0 1 3 3 3 5 5 7 7]\n",
      "Region chr5:139-159: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2], [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 2]\n",
      "Region chr5:248-268: [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0]\n",
      "Region chr6:20-40: [1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 3, 4, 4, 4, 4, 8], [1 1 1 1 2 2 2 2 2 2 2 2 4 4 3 4 4 4 4 8]\n",
      "Region chr6:68-88: [0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 0, 1, 1], [0 0 0 1 1 1 1 2 2 2 2 2 2 1 1 1 1 0 1 1]\n",
      "Region chr7:72-92: [4, 4, 5, 3, 2, 3, 2, 2, 4, 5, 5, 7, 6, 7, 7, 6, 6, 7, 5, 4], [4 4 5 3 2 3 2 2 4 5 5 7 6 7 7 6 6 7 5 4]\n",
      "Region chr7:157-177: [2, 2, 2, 2, 3, 4, 3, 4, 3, 3, 3, 4, 4, 5, 4, 3, 3, 2, 2, 3], [2 2 2 2 3 4 3 4 3 3 3 4 4 5 4 3 3 2 2 3]\n",
      "Testing /cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/simulated3.bam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 8589.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region chr1:23-43: [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2], [1 1 1 1 1 1 1 1 0 0 0 0 0 2 2 2 2 2 2 2]\n",
      "Region chr1:65-85: [4, 4, 5, 4, 4, 5, 6, 5, 5, 5, 5, 5, 4, 4, 4, 4, 3, 4, 4, 4], [4 4 5 4 4 5 6 5 5 5 5 5 4 4 4 4 3 4 4 4]\n",
      "Region chr2:54-74: [1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 3, 2, 2, 2, 2, 2], [1 1 1 1 1 2 2 2 2 1 1 1 1 1 3 2 2 2 2 2]\n",
      "Region chr2:127-147: [2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1], [2 2 1 1 1 1 1 2 2 2 1 1 1 1 1 2 2 1 1 1]\n",
      "Region chr3:33-53: [1, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2], [1 0 0 0 0 0 1 2 2 2 2 2 2 2 3 3 2 2 2 2]\n",
      "Region chr3:80-100: [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1], [1 1 1 1 1 1 1 1 1 2 2 2 2 2 1 1 1 1 1 1]\n",
      "Region chr4:13-33: [5, 4, 4, 3, 2, 3, 3, 3, 3, 4, 4, 5, 5, 6, 6, 5, 4, 4, 3, 2], [5 4 4 3 2 3 3 3 3 4 4 5 5 6 6 5 4 4 3 2]\n",
      "Region chr4:55-75: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 2, 3, 3, 4, 4, 4, 3], [0 0 0 0 0 0 0 0 0 1 1 1 2 2 3 3 4 4 4 3]\n",
      "Region chr5:139-159: [3, 2, 2, 3, 4, 4, 4, 5, 5, 5, 5, 7, 7, 6, 5, 6, 6, 5, 6, 7], [3 2 2 3 4 4 4 5 5 5 5 7 7 6 5 6 6 5 6 7]\n",
      "Region chr5:248-268: [4, 4, 4, 4, 2, 1, 1, 1, 2, 4, 5, 5, 7, 7, 7, 7, 8, 7, 6, 4], [4 4 4 4 2 1 1 1 2 4 5 5 7 7 7 7 8 7 6 4]\n",
      "Region chr6:20-40: [1, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1], [1 0 0 0 0 0 1 1 2 2 2 2 2 2 2 2 1 2 1 1]\n",
      "Region chr6:68-88: [3, 3, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 1, 1, 1], [3 3 1 1 1 1 1 3 3 3 3 3 4 4 4 4 4 1 1 1]\n",
      "Region chr7:72-92: [2, 2, 1, 1, 0, 1, 1, 2, 2, 4, 4, 4, 4, 4, 4, 3, 3, 2, 2, 0], [2 2 1 1 0 1 1 2 2 4 4 4 4 4 4 3 3 2 2 0]\n",
      "Region chr7:157-177: [1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1], [1 1 1 1 1 1 1 2 2 2 2 2 1 1 1 1 1 1 1 1]\n",
      "Testing /cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/simulated4.bam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 8262.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region chr1:23-43: [1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 2], [1 1 1 1 1 1 0 0 0 1 1 2 2 2 2 3 3 3 3 2]\n",
      "Region chr1:65-85: [4, 3, 3, 2, 1, 0, 1, 1, 1, 2, 3, 3, 3, 3, 3, 3, 2, 2, 2, 1], [4 3 3 2 1 0 1 1 1 2 3 3 3 3 3 3 2 2 2 1]\n",
      "Region chr2:54-74: [1, 1, 1, 0, 1, 1, 1, 1, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 1, 2], [1 1 1 0 1 1 1 1 3 3 3 3 3 4 3 3 3 3 1 2]\n",
      "Region chr2:127-147: [2, 2, 2, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 2, 2, 3, 3], [2 2 2 3 3 3 4 4 4 4 4 4 4 3 3 3 2 2 3 3]\n",
      "Region chr3:33-53: [1, 1, 2, 2, 2, 2, 2, 3, 4, 5, 4, 4, 3, 3, 3, 4, 4, 4, 3, 2], [1 1 2 2 2 2 2 3 4 5 4 4 3 3 3 4 4 4 3 2]\n",
      "Region chr3:80-100: [2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2], [2 2 2 2 2 2 2 3 3 3 2 2 1 1 1 2 2 2 2 2]\n",
      "Region chr4:13-33: [5, 5, 4, 4, 4, 4, 4, 3, 2, 2, 3, 3, 5, 6, 6, 5, 6, 5, 5, 6], [5 5 4 4 4 4 4 3 2 2 3 3 5 6 6 5 6 5 5 6]\n",
      "Region chr4:55-75: [1, 1, 1, 1, 1, 2, 2, 2, 3, 5, 5, 5, 4, 4, 4, 3, 4, 6, 5, 3], [1 1 1 1 1 2 2 2 3 5 5 5 4 4 4 3 4 6 5 3]\n",
      "Region chr5:139-159: [4, 4, 2, 2, 3, 2, 3, 5, 6, 7, 7, 7, 7, 7, 6, 7, 6, 5, 5, 5], [4 4 2 2 3 2 3 5 6 7 7 7 7 7 6 7 6 5 5 5]\n",
      "Region chr5:248-268: [2, 2, 3, 3, 2, 2, 2, 3, 3, 3, 3, 4, 3, 3, 4, 4, 4, 4, 4, 3], [2 2 3 3 2 2 2 3 3 3 3 4 3 3 4 4 4 4 4 3]\n",
      "Region chr6:20-40: [0, 1, 2, 2, 2, 2, 2, 3, 3, 3, 4, 3, 3, 3, 3, 3, 4, 5, 6, 6], [0 1 2 2 2 2 2 3 3 3 4 3 3 3 3 3 4 5 6 6]\n",
      "Region chr6:68-88: [3, 3, 4, 3, 4, 5, 4, 4, 5, 5, 5, 6, 6, 6, 5, 4, 4, 4, 3, 4], [3 3 4 3 4 5 4 4 5 5 5 6 6 6 5 4 4 4 3 4]\n",
      "Region chr7:72-92: [1, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 0, 1], [1 0 0 0 0 0 1 1 2 2 2 2 2 2 2 2 1 1 0 1]\n",
      "Region chr7:157-177: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1]\n",
      "Testing /cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/simulated5.bam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 13787.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region chr1:23-43: [4, 3, 3, 2, 2, 3, 5, 4, 5, 5, 4, 4, 6, 7, 7, 7, 5, 5, 4, 5], [4 3 3 2 2 3 5 4 5 5 4 4 6 7 7 7 5 5 4 5]\n",
      "Region chr1:65-85: [3, 3, 2, 3, 3, 6, 4, 5, 5, 5, 5, 6, 6, 5, 6, 3, 4, 3, 4, 4], [3 3 2 3 3 6 4 5 5 5 5 6 6 5 6 3 4 3 4 4]\n",
      "Region chr2:54-74: [2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 3, 3, 3, 3, 2], [2 2 2 2 1 1 1 1 1 2 1 1 1 1 2 3 3 3 3 2]\n",
      "Region chr2:127-147: [2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 3, 3], [2 2 2 2 2 2 2 2 0 0 0 0 0 2 2 2 2 2 3 3]\n",
      "Region chr3:33-53: [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0], [0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0]\n",
      "Region chr3:80-100: [2, 2, 2, 2, 2, 1, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2], [2 2 2 2 2 1 0 0 0 0 1 2 2 2 2 2 2 2 2 2]\n",
      "Region chr4:13-33: [2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2], [2 2 2 2 2 2 2 2 2 1 0 0 0 0 1 2 2 2 2 2]\n",
      "Region chr4:55-75: [0, 1, 2, 3, 3, 3, 3, 3, 3, 3, 3, 2, 1, 0, 0, 0, 1, 2, 3, 3], [0 1 2 3 3 3 3 3 3 3 3 2 1 0 0 0 1 2 3 3]\n",
      "Region chr5:139-159: [3, 2, 2, 2, 2, 2, 4, 4, 4, 4, 3, 3, 3, 4, 5, 6, 5, 5, 5, 4], [3 2 2 2 2 2 4 4 4 4 3 3 3 4 5 6 5 5 5 4]\n",
      "Region chr5:248-268: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1], [0 0 0 0 0 0 0 0 0 1 1 2 2 2 2 2 2 2 2 1]\n",
      "Region chr6:20-40: [1, 2, 2, 2, 1, 2, 2, 2, 2, 5, 6, 6, 7, 7, 7, 6, 7, 7, 7, 4], [1 2 2 2 1 2 2 2 2 5 6 6 7 7 7 6 7 7 7 4]\n",
      "Region chr6:68-88: [3, 2, 2, 1, 1, 1, 4, 4, 5, 5, 5, 4, 4, 4, 4, 4, 2, 2, 1, 1], [3 2 2 1 1 1 4 4 5 5 5 4 4 4 4 4 2 2 1 1]\n",
      "Region chr7:72-92: [1, 2, 1, 1, 1, 2, 2, 3, 3, 3, 3, 2, 2, 2, 3, 2, 3, 2, 3, 3], [1 2 1 1 1 2 2 3 3 3 3 2 2 2 3 2 3 2 3 3]\n",
      "Region chr7:157-177: [2, 2, 3, 3, 3, 4, 4, 3, 3, 3, 3, 4, 6, 6, 6, 5, 4, 5, 5, 5], [2 2 3 3 3 4 4 3 3 3 3 4 6 6 6 5 4 5 5 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 13605.25it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 14614.30it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 10276.56it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 13659.05it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 10292.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing /cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/simulated1.bam\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "Testing /cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/simulated2.bam\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "Testing /cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/simulated3.bam\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "Testing /cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/simulated4.bam\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "Testing /cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/simulated5.bam\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "(5,)\n",
      "All tests passed successfully!\n"
     ]
    }
   ],
   "source": [
    "test_BAM(bams, fixed_bed_in, new_cov, out, batch_size=50, sequence_dim=\"_sequence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing /cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/simulated1.bam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 12925.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region chr1:23-43: [2, 2, 2, 2, 1, 1, 2, 1, 1, 2, 2, 2, 3, 3, 3, 3, 2, 2, 2, 1], [2 2 2 2 1 1 2 1 1 2 2 2 3 3 3 3 2 2 2 1]\n",
      "Region chr1:65-85: [2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 4, 4, 3, 3, 5, 5], [2 1 1 2 2 2 2 2 2 2 2 3 3 2 4 4 3 3 5 5]\n",
      "Region chr2:54-74: [1, 1, 1, 1, 2, 3, 2, 3, 3, 3, 4, 5, 5, 5, 4, 3, 3, 2, 3, 4], [1 1 1 1 2 3 2 3 3 3 4 5 5 5 4 3 3 2 3 4]\n",
      "Region chr2:127-147: [1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0], [1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0]\n",
      "Region chr3:33-53: [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0], [0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0]\n",
      "Region chr3:80-100: [2, 2, 2, 3, 3, 4, 3, 2, 2, 2, 2, 3, 4, 3, 3, 2, 2, 2, 3, 3], [2 2 2 3 3 4 3 2 2 2 2 3 4 3 3 2 2 2 3 3]\n",
      "Region chr4:13-33: [3, 4, 4, 4, 4, 5, 5, 3, 3, 3, 3, 3, 6, 6, 6, 5, 6, 5, 5, 5], [3 4 4 4 4 5 5 3 3 3 3 3 6 6 6 5 6 5 5 5]\n",
      "Region chr4:55-75: [3, 3, 3, 3, 3, 3, 3, 2, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 4, 4], [3 3 3 3 3 3 3 2 4 4 4 4 5 5 5 5 6 6 4 4]\n",
      "Region chr5:139-159: [0, 0, 1, 1, 1, 1, 1, 1, 2, 3, 3, 3, 2, 2, 2, 2, 2, 4, 3, 2], [0 0 1 1 1 1 1 1 2 3 3 3 2 2 2 2 2 4 3 2]\n",
      "Region chr5:248-268: [1, 2, 1, 1, 1, 2, 2, 3, 3, 3, 3, 2, 2, 3, 3, 4, 6, 5, 5, 5], [1 2 1 1 1 2 2 3 3 3 3 2 2 3 3 4 6 5 5 5]\n",
      "Region chr6:20-40: [4, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 3, 3, 5, 5, 7, 6, 6, 7, 7], [4 3 3 3 3 2 2 2 2 2 2 3 3 5 5 7 6 6 7 7]\n",
      "Region chr6:68-88: [3, 3, 2, 2, 3, 4, 4, 5, 5, 5, 3, 3, 3, 3, 2, 3, 3, 2, 2, 3], [3 3 2 2 3 4 4 5 5 5 3 3 3 3 2 3 3 2 2 3]\n",
      "Region chr7:72-92: [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2], [0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 2]\n",
      "Region chr7:157-177: [1, 1, 1, 2, 2, 3, 3, 4, 3, 3, 3, 3, 5, 5, 6, 5, 5, 4, 5, 5], [1 1 1 2 2 3 3 4 3 3 3 3 5 5 6 5 5 4 5 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 12638.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing /cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/simulated1.bam\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1,)\n",
      "All tests passed successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_BAM([bams[0]], fixed_bed_in, {\"simulated1.bam\": new_cov[\"simulated1.bam\"]}, out, batch_size=50, sequence_dim=\"_sequence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `BigWig`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_BigWig(bigwig_files, bed_file, chromsizes_file, coverages, temp_dir, batch_size=50, sequence_dim=\"_sequence\", fixed_length=False, length_dim=None):\n",
    "    \"\"\"\n",
    "    Tests the BigWig class for one or more input BigWig files.\n",
    "\n",
    "    Parameters:\n",
    "        bigwig_files (list): List of paths to BigWig files.\n",
    "        bed_file (str or Path): Path to the BED file.\n",
    "        chromsizes_file (str or Path): Path to the chromsizes file.\n",
    "        coverage_file (str or Path): Path to the pickled coverage file.\n",
    "        temp_dir (str or Path): Directory where temporary files will be stored.\n",
    "        batch_size (int): Batch size for the BigWig reader.\n",
    "        sequence_dim (str): Name of the sequence dimension in the Zarr output.\n",
    "\n",
    "    Raises:\n",
    "        AssertionError: If any test fails.\n",
    "    \"\"\"\n",
    "    temp_dir = Path(temp_dir)\n",
    "    temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    bigwig_out = temp_dir / 'output.bigwig.zarr'\n",
    "\n",
    "    # Load chromsizes\n",
    "    chromsizes = {}\n",
    "    with open(chromsizes_file) as f:\n",
    "        for line in f:\n",
    "            chrom, size = line.strip().split()\n",
    "            chromsizes[chrom] = int(size)\n",
    "\n",
    "    # Test instantiation of the BigWig reader class\n",
    "    bigwig_reader = BigWig(\n",
    "        name=\"cov\",\n",
    "        bigwigs=bigwig_files,\n",
    "        samples=[bigwig.name for bigwig in bigwig_files],\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    assert isinstance(bigwig_reader, BigWig), \"BigWig reader instantiation failed.\"\n",
    "\n",
    "    # Read in the BED file\n",
    "    bed = pd.read_csv(bed_file, sep=\"\\t\", header=None)\n",
    "\n",
    "    # Verify each BigWig file individually\n",
    "    for bigwig_file in bigwig_files:\n",
    "        bigwig_name = bigwig_file.name\n",
    "        iterator = bigwig_reader._reader(\n",
    "            bed=bed,\n",
    "            f=pyBigWig.open(str(bigwig_file)),\n",
    "            contig_lengths=chromsizes\n",
    "        )\n",
    "        _read = [list(seq) for seq in iterator]\n",
    "\n",
    "        # Verify that the data matches the expected coverage\n",
    "        for i, (region, coverage) in enumerate(coverages[bigwig_name].items()):\n",
    "            print(f\"Region {region}: {list(_read[i])}, {coverage}\")\n",
    "            assert np.array_equal(coverage, _read[i]), f\"Region {region} in {bigwig_name} does not match.\"\n",
    "\n",
    "        # Close the BigWig file\n",
    "        iterator.close()\n",
    "\n",
    "    # Test writing to Zarr\n",
    "    bed[\"strand\"] = \"+\"\n",
    "    bigwig_reader._write(\n",
    "        bigwig_out,\n",
    "        bed=bed,\n",
    "        fixed_length=fixed_length,\n",
    "        sequence_dim=sequence_dim,\n",
    "        length_dim=length_dim,\n",
    "        overwrite=True\n",
    "    )\n",
    "    zarr.consolidate_metadata(bigwig_out)\n",
    "\n",
    "    # Test round-trip reading\n",
    "    data = sd.open_zarr(bigwig_out)\n",
    "    print(data)\n",
    "    \n",
    "    # Verify that the data matches the expected coverage for all regions\n",
    "    for file_index, bigwig_file in enumerate(bigwig_files):\n",
    "        print(f\"Testing {bigwig_file}\")\n",
    "        bigwig_name = bigwig_file.name\n",
    "        for region_index, (region, coverage) in enumerate(coverages[bigwig_name].items()):\n",
    "            print(data['cov'][region_index].shape)\n",
    "            assert np.array_equal(coverage, data[\"cov\"].values[region_index, file_index]), f\"Region {region} in {bigwig_name} does not match.\"\n",
    "\n",
    "    # Clean up temporary files\n",
    "    for f in temp_dir.iterdir():\n",
    "        if f.is_dir():\n",
    "            os.system(f'rm -r {f}')\n",
    "        else:\n",
    "            f.unlink()\n",
    "\n",
    "    print(\"All tests passed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of bigwigs with simulated{1-5}.bw\n",
    "bigwigs = [Path(sd.__file__).resolve().parent.parent / 'tests' / 'data' / f'simulated{i}.bw' for i in range(1, 6)]\n",
    "chromsizes = Path(sd.__file__).resolve().parent.parent / 'tests' / 'data' / 'variable.chrom.sizes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify new cov to have .bw instead of .bam in keys\n",
    "new_cov_bw = {}\n",
    "for key, value in new_cov.items():\n",
    "    new_cov_bw[key.replace(\".bam\", \".bw\")] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 30856.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region chr1:23-43: [2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 1.0], [2 2 2 2 1 1 2 1 1 2 2 2 3 3 3 3 2 2 2 1]\n",
      "Region chr1:65-85: [2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 4.0, 4.0, 3.0, 3.0, 5.0, 5.0], [2 1 1 2 2 2 2 2 2 2 2 3 3 2 4 4 3 3 5 5]\n",
      "Region chr2:54-74: [1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 4.0, 5.0, 5.0, 5.0, 4.0, 3.0, 3.0, 2.0, 3.0, 4.0], [1 1 1 1 2 3 2 3 3 3 4 5 5 5 4 3 3 2 3 4]\n",
      "Region chr2:127-147: [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0], [1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0]\n",
      "Region chr3:33-53: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0]\n",
      "Region chr3:80-100: [2.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 2.0, 2.0, 2.0, 2.0, 3.0, 4.0, 3.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0], [2 2 2 3 3 4 3 2 2 2 2 3 4 3 3 2 2 2 3 3]\n",
      "Region chr4:13-33: [3.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 3.0, 3.0, 3.0, 3.0, 3.0, 6.0, 6.0, 6.0, 5.0, 6.0, 5.0, 5.0, 5.0], [3 4 4 4 4 5 5 3 3 3 3 3 6 6 6 5 6 5 5 5]\n",
      "Region chr4:55-75: [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 6.0, 6.0, 4.0, 4.0], [3 3 3 3 3 3 3 2 4 4 4 4 5 5 5 5 6 6 4 4]\n",
      "Region chr5:139-159: [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 4.0, 3.0, 2.0], [0 0 1 1 1 1 1 1 2 3 3 3 2 2 2 2 2 4 3 2]\n",
      "Region chr5:248-268: [1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 4.0, 6.0, 5.0, 5.0, 5.0], [1 2 1 1 1 2 2 3 3 3 3 2 2 3 3 4 6 5 5 5]\n",
      "Region chr6:20-40: [4.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 5.0, 5.0, 7.0, 6.0, 6.0, 7.0, 7.0], [4 3 3 3 3 2 2 2 2 2 2 3 3 5 5 7 6 6 7 7]\n",
      "Region chr6:68-88: [3.0, 3.0, 2.0, 2.0, 3.0, 4.0, 4.0, 5.0, 5.0, 5.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 2.0, 3.0], [3 3 2 2 3 4 4 5 5 5 3 3 3 3 2 3 3 2 2 3]\n",
      "Region chr7:72-92: [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0], [0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 2]\n",
      "Region chr7:157-177: [1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 5.0, 5.0, 6.0, 5.0, 5.0, 4.0, 5.0, 5.0], [1 1 1 2 2 3 3 4 3 3 3 3 5 5 6 5 5 4 5 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 19189.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region chr1:23-43: [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]\n",
      "Region chr1:65-85: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0], [1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 2 2 2 2 2]\n",
      "Region chr2:54-74: [2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 3.0, 4.0, 4.0, 4.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 2.0], [2 2 1 2 2 2 3 4 4 4 3 3 3 2 2 3 2 1 2 2]\n",
      "Region chr2:127-147: [2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 5.0, 5.0, 6.0, 5.0, 3.0, 4.0, 4.0], [2 1 0 0 0 0 1 3 3 3 3 3 3 5 5 6 5 3 4 4]\n",
      "Region chr3:33-53: [1.0, 2.0, 2.0, 2.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 5.0, 5.0, 6.0], [1 2 2 2 3 4 4 4 4 4 4 3 3 3 3 3 4 5 5 6]\n",
      "Region chr3:80-100: [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]\n",
      "Region chr4:13-33: [2.0, 3.0, 3.0, 3.0, 2.0, 1.0, 4.0, 4.0, 4.0, 5.0, 6.0, 5.0, 5.0, 5.0, 5.0, 5.0, 3.0, 3.0, 3.0, 2.0], [2 3 3 3 2 1 4 4 4 5 6 5 5 5 5 5 3 3 3 2]\n",
      "Region chr4:55-75: [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 3.0, 3.0, 3.0, 5.0, 5.0, 7.0, 7.0], [0 1 1 1 1 1 1 1 1 1 1 0 1 3 3 3 5 5 7 7]\n",
      "Region chr5:139-159: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0], [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 2]\n",
      "Region chr5:248-268: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0], [0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0]\n",
      "Region chr6:20-40: [1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 4.0, 4.0, 3.0, 4.0, 4.0, 4.0, 4.0, 8.0], [1 1 1 1 2 2 2 2 2 2 2 2 4 4 3 4 4 4 4 8]\n",
      "Region chr6:68-88: [0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0], [0 0 0 1 1 1 1 2 2 2 2 2 2 1 1 1 1 0 1 1]\n",
      "Region chr7:72-92: [4.0, 4.0, 5.0, 3.0, 2.0, 3.0, 2.0, 2.0, 4.0, 5.0, 5.0, 7.0, 6.0, 7.0, 7.0, 6.0, 6.0, 7.0, 5.0, 4.0], [4 4 5 3 2 3 2 2 4 5 5 7 6 7 7 6 6 7 5 4]\n",
      "Region chr7:157-177: [2.0, 2.0, 2.0, 2.0, 3.0, 4.0, 3.0, 4.0, 3.0, 3.0, 3.0, 4.0, 4.0, 5.0, 4.0, 3.0, 3.0, 2.0, 2.0, 3.0], [2 2 2 2 3 4 3 4 3 3 3 4 4 5 4 3 3 2 2 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 17681.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region chr1:23-43: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0], [1 1 1 1 1 1 1 1 0 0 0 0 0 2 2 2 2 2 2 2]\n",
      "Region chr1:65-85: [4.0, 4.0, 5.0, 4.0, 4.0, 5.0, 6.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 4.0, 4.0, 4.0, 3.0, 4.0, 4.0, 4.0], [4 4 5 4 4 5 6 5 5 5 5 5 4 4 4 4 3 4 4 4]\n",
      "Region chr2:54-74: [1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0], [1 1 1 1 1 2 2 2 2 1 1 1 1 1 3 2 2 2 2 2]\n",
      "Region chr2:127-147: [2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0], [2 2 1 1 1 1 1 2 2 2 1 1 1 1 1 2 2 1 1 1]\n",
      "Region chr3:33-53: [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0], [1 0 0 0 0 0 1 2 2 2 2 2 2 2 3 3 2 2 2 2]\n",
      "Region chr3:80-100: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1 1 1 1 1 1 1 1 1 2 2 2 2 2 1 1 1 1 1 1]\n",
      "Region chr4:13-33: [5.0, 4.0, 4.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 5.0, 5.0, 6.0, 6.0, 5.0, 4.0, 4.0, 3.0, 2.0], [5 4 4 3 2 3 3 3 3 4 4 5 5 6 6 5 4 4 3 2]\n",
      "Region chr4:55-75: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 4.0, 4.0, 3.0], [0 0 0 0 0 0 0 0 0 1 1 1 2 2 3 3 4 4 4 3]\n",
      "Region chr5:139-159: [3.0, 2.0, 2.0, 3.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 7.0, 7.0, 6.0, 5.0, 6.0, 6.0, 5.0, 6.0, 7.0], [3 2 2 3 4 4 4 5 5 5 5 7 7 6 5 6 6 5 6 7]\n",
      "Region chr5:248-268: [4.0, 4.0, 4.0, 4.0, 2.0, 1.0, 1.0, 1.0, 2.0, 4.0, 5.0, 5.0, 7.0, 7.0, 7.0, 7.0, 8.0, 7.0, 6.0, 4.0], [4 4 4 4 2 1 1 1 2 4 5 5 7 7 7 7 8 7 6 4]\n",
      "Region chr6:20-40: [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0], [1 0 0 0 0 0 1 1 2 2 2 2 2 2 2 2 1 2 1 1]\n",
      "Region chr6:68-88: [3.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 1.0, 1.0, 1.0], [3 3 1 1 1 1 1 3 3 3 3 3 4 4 4 4 4 1 1 1]\n",
      "Region chr7:72-92: [2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 2.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.0, 3.0, 2.0, 2.0, 0.0], [2 2 1 1 0 1 1 2 2 4 4 4 4 4 4 3 3 2 2 0]\n",
      "Region chr7:157-177: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1 1 1 1 1 1 1 2 2 2 2 2 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 18292.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region chr1:23-43: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0], [1 1 1 1 1 1 0 0 0 1 1 2 2 2 2 3 3 3 3 2]\n",
      "Region chr1:65-85: [4.0, 3.0, 3.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 1.0], [4 3 3 2 1 0 1 1 1 2 3 3 3 3 3 3 2 2 2 1]\n",
      "Region chr2:54-74: [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 1.0, 2.0], [1 1 1 0 1 1 1 1 3 3 3 3 3 4 3 3 3 3 1 2]\n",
      "Region chr2:127-147: [2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0], [2 2 2 3 3 3 4 4 4 4 4 4 4 3 3 3 2 2 3 3]\n",
      "Region chr3:33-53: [1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 4.0, 5.0, 4.0, 4.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 3.0, 2.0], [1 1 2 2 2 2 2 3 4 5 4 4 3 3 3 4 4 4 3 2]\n",
      "Region chr3:80-100: [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0], [2 2 2 2 2 2 2 3 3 3 2 2 1 1 1 2 2 2 2 2]\n",
      "Region chr4:13-33: [5.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.0, 2.0, 2.0, 3.0, 3.0, 5.0, 6.0, 6.0, 5.0, 6.0, 5.0, 5.0, 6.0], [5 5 4 4 4 4 4 3 2 2 3 3 5 6 6 5 6 5 5 6]\n",
      "Region chr4:55-75: [1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 5.0, 5.0, 5.0, 4.0, 4.0, 4.0, 3.0, 4.0, 6.0, 5.0, 3.0], [1 1 1 1 1 2 2 2 3 5 5 5 4 4 4 3 4 6 5 3]\n",
      "Region chr5:139-159: [4.0, 4.0, 2.0, 2.0, 3.0, 2.0, 3.0, 5.0, 6.0, 7.0, 7.0, 7.0, 7.0, 7.0, 6.0, 7.0, 6.0, 5.0, 5.0, 5.0], [4 4 2 2 3 2 3 5 6 7 7 7 7 7 6 7 6 5 5 5]\n",
      "Region chr5:248-268: [2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.0], [2 2 3 3 2 2 2 3 3 3 3 4 3 3 4 4 4 4 4 3]\n",
      "Region chr6:20-40: [0.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 5.0, 6.0, 6.0], [0 1 2 2 2 2 2 3 3 3 4 3 3 3 3 3 4 5 6 6]\n",
      "Region chr6:68-88: [3.0, 3.0, 4.0, 3.0, 4.0, 5.0, 4.0, 4.0, 5.0, 5.0, 5.0, 6.0, 6.0, 6.0, 5.0, 4.0, 4.0, 4.0, 3.0, 4.0], [3 3 4 3 4 5 4 4 5 5 5 6 6 6 5 4 4 4 3 4]\n",
      "Region chr7:72-92: [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0], [1 0 0 0 0 0 1 1 2 2 2 2 2 2 2 2 1 1 0 1]\n",
      "Region chr7:157-177: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 18230.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region chr1:23-43: [4.0, 3.0, 3.0, 2.0, 2.0, 3.0, 5.0, 4.0, 5.0, 5.0, 4.0, 4.0, 6.0, 7.0, 7.0, 7.0, 5.0, 5.0, 4.0, 5.0], [4 3 3 2 2 3 5 4 5 5 4 4 6 7 7 7 5 5 4 5]\n",
      "Region chr1:65-85: [3.0, 3.0, 2.0, 3.0, 3.0, 6.0, 4.0, 5.0, 5.0, 5.0, 5.0, 6.0, 6.0, 5.0, 6.0, 3.0, 4.0, 3.0, 4.0, 4.0], [3 3 2 3 3 6 4 5 5 5 5 6 6 5 6 3 4 3 4 4]\n",
      "Region chr2:54-74: [2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0], [2 2 2 2 1 1 1 1 1 2 1 1 1 1 2 3 3 3 3 2]\n",
      "Region chr2:127-147: [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0], [2 2 2 2 2 2 2 2 0 0 0 0 0 2 2 2 2 2 3 3]\n",
      "Region chr3:33-53: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0]\n",
      "Region chr3:80-100: [2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0], [2 2 2 2 2 1 0 0 0 0 1 2 2 2 2 2 2 2 2 2]\n",
      "Region chr4:13-33: [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0], [2 2 2 2 2 2 2 2 2 1 0 0 0 0 1 2 2 2 2 2]\n",
      "Region chr4:55-75: [0.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 3.0, 3.0], [0 1 2 3 3 3 3 3 3 3 3 2 1 0 0 0 1 2 3 3]\n",
      "Region chr5:139-159: [3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 4.0, 4.0, 4.0, 4.0, 3.0, 3.0, 3.0, 4.0, 5.0, 6.0, 5.0, 5.0, 5.0, 4.0], [3 2 2 2 2 2 4 4 4 4 3 3 3 4 5 6 5 5 5 4]\n",
      "Region chr5:248-268: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0], [0 0 0 0 0 0 0 0 0 1 1 2 2 2 2 2 2 2 2 1]\n",
      "Region chr6:20-40: [1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 5.0, 6.0, 6.0, 7.0, 7.0, 7.0, 6.0, 7.0, 7.0, 7.0, 4.0], [1 2 2 2 1 2 2 2 2 5 6 6 7 7 7 6 7 7 7 4]\n",
      "Region chr6:68-88: [3.0, 2.0, 2.0, 1.0, 1.0, 1.0, 4.0, 4.0, 5.0, 5.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 2.0, 2.0, 1.0, 1.0], [3 2 2 1 1 1 4 4 5 5 5 4 4 4 4 4 2 2 1 1]\n",
      "Region chr7:72-92: [1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0], [1 2 1 1 1 2 2 3 3 3 3 2 2 2 3 2 3 2 3 3]\n",
      "Region chr7:157-177: [2.0, 2.0, 3.0, 3.0, 3.0, 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 4.0, 6.0, 6.0, 6.0, 5.0, 4.0, 5.0, 5.0, 5.0], [2 2 3 3 3 4 4 3 3 3 3 4 6 6 6 5 4 5 5 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 18850.80it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 28855.16it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 38682.65it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 16748.50it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 16782.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 6kB\n",
      "Dimensions:     (_sequence: 14, cov_sample: 5, _length: 20)\n",
      "Coordinates:\n",
      "  * cov_sample  (cov_sample) object 40B 'simulated1.bw' ... 'simulated5.bw'\n",
      "Dimensions without coordinates: _sequence, _length\n",
      "Data variables:\n",
      "    cov         (_sequence, cov_sample, _length) float32 6kB dask.array<chunksize=(14, 1, 20), meta=np.ndarray>\n",
      "Testing /cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/simulated1.bw\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "Testing /cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/simulated2.bw\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "Testing /cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/simulated3.bw\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "Testing /cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/simulated4.bw\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "Testing /cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/simulated5.bw\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "(5, 20)\n",
      "All tests passed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Test the BigWig class on variable length sequences\n",
    "data = test_BigWig(bigwigs, fixed_bed_in, chromsizes, new_cov_bw, out, batch_size=50, fixed_length=20, sequence_dim=\"_sequence\", length_dim=\"_length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 29214.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region chr1:23-43: [2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 1.0], [2 2 2 2 1 1 2 1 1 2 2 2 3 3 3 3 2 2 2 1]\n",
      "Region chr1:65-85: [2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 4.0, 4.0, 3.0, 3.0, 5.0, 5.0], [2 1 1 2 2 2 2 2 2 2 2 3 3 2 4 4 3 3 5 5]\n",
      "Region chr2:54-74: [1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 4.0, 5.0, 5.0, 5.0, 4.0, 3.0, 3.0, 2.0, 3.0, 4.0], [1 1 1 1 2 3 2 3 3 3 4 5 5 5 4 3 3 2 3 4]\n",
      "Region chr2:127-147: [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0], [1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0]\n",
      "Region chr3:33-53: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0]\n",
      "Region chr3:80-100: [2.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 2.0, 2.0, 2.0, 2.0, 3.0, 4.0, 3.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0], [2 2 2 3 3 4 3 2 2 2 2 3 4 3 3 2 2 2 3 3]\n",
      "Region chr4:13-33: [3.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 3.0, 3.0, 3.0, 3.0, 3.0, 6.0, 6.0, 6.0, 5.0, 6.0, 5.0, 5.0, 5.0], [3 4 4 4 4 5 5 3 3 3 3 3 6 6 6 5 6 5 5 5]\n",
      "Region chr4:55-75: [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 6.0, 6.0, 4.0, 4.0], [3 3 3 3 3 3 3 2 4 4 4 4 5 5 5 5 6 6 4 4]\n",
      "Region chr5:139-159: [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 4.0, 3.0, 2.0], [0 0 1 1 1 1 1 1 2 3 3 3 2 2 2 2 2 4 3 2]\n",
      "Region chr5:248-268: [1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 4.0, 6.0, 5.0, 5.0, 5.0], [1 2 1 1 1 2 2 3 3 3 3 2 2 3 3 4 6 5 5 5]\n",
      "Region chr6:20-40: [4.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 5.0, 5.0, 7.0, 6.0, 6.0, 7.0, 7.0], [4 3 3 3 3 2 2 2 2 2 2 3 3 5 5 7 6 6 7 7]\n",
      "Region chr6:68-88: [3.0, 3.0, 2.0, 2.0, 3.0, 4.0, 4.0, 5.0, 5.0, 5.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 2.0, 3.0], [3 3 2 2 3 4 4 5 5 5 3 3 3 3 2 3 3 2 2 3]\n",
      "Region chr7:72-92: [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0], [0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 2]\n",
      "Region chr7:157-177: [1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 5.0, 5.0, 6.0, 5.0, 5.0, 4.0, 5.0, 5.0], [1 1 1 2 2 3 3 4 3 3 3 3 5 5 6 5 5 4 5 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Make chromsizes a list of tuples\n",
    "chromsizes = {}\n",
    "with open(Path(sd.__file__).resolve().parent.parent / 'tests' / 'data' / 'variable.chrom.sizes') as f:\n",
    "    for line in f:\n",
    "        chrom, size = line.strip().split()\n",
    "        chromsizes[chrom] = int(size)\n",
    "chromsizes\n",
    "\n",
    "bigwig_reader = BigWig(\n",
    "    name=\"cov\",\n",
    "    bigwigs=bigwigs,\n",
    "    samples=[bigwig.name for bigwig in bigwigs],\n",
    "    batch_size=50\n",
    ")\n",
    "assert isinstance(bigwig_reader, BigWig), \"bigwig reader instantiation failed.\"\n",
    "\n",
    "iterator = bigwig_reader._reader(\n",
    "    bed=bed,\n",
    "    f=pyBigWig.open(str(bigwigs[0])),\n",
    "    contig_lengths=chromsizes\n",
    ")\n",
    "\n",
    "_read = [list(seq) for seq in iterator]\n",
    "\n",
    "# Verify that the data matches the expected coverage\n",
    "for i, (region, coverage) in enumerate(new_cov[bigwigs[0].name.replace(\".bw\", \".bam\")].items()):\n",
    "    print(f\"Region {region}: {list(_read[i])}, {coverage}\")\n",
    "    assert np.array_equal(coverage, _read[i]), f\"Region {region} in {bigwigs[0].name} does not match.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `from_region_files`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqdata import from_region_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_from_region_files(\n",
    "    *readers, \n",
    "    names,\n",
    "    true_seqs,\n",
    "    true_covs,\n",
    "    temp_dir, \n",
    "    fixed_length=False, \n",
    "    length_dim=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Tests the FlatFASTA class for a single input FASTA file.\n",
    "\n",
    "    Parameters:\n",
    "        input_fasta (str or Path): Path to the input FASTA file.\n",
    "        temp_dir (str or Path): Directory where temporary files will be stored.\n",
    "        batch_size (int): Batch size for the FlatFASTA reader.\n",
    "        fixed_length (bool): Whether to use fixed-length sequences when writing to Zarr.\n",
    "        length_dim (str): Name of the length dimension in the Zarr output.\n",
    "\n",
    "    Raises:\n",
    "        AssertionError: If any test fails.\n",
    "    \"\"\"\n",
    "    temp_dir = Path(temp_dir)\n",
    "    temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out = temp_dir / 'output.zarr'\n",
    "\n",
    "    data = from_region_files(\n",
    "        *readers,\n",
    "        path=out,\n",
    "        sequence_dim=\"_sequence\",\n",
    "        fixed_length=fixed_length,\n",
    "        overwrite=True,\n",
    "        length_dim=length_dim\n",
    "    )\n",
    "\n",
    "    # Verify that the data is the same\n",
    "    for i, name in enumerate(names):\n",
    "        if fixed_length:\n",
    "            seqs = [''.join(row.astype(str)) for row in data[name].values]\n",
    "        else:\n",
    "            seqs = data[name].values.astype(str)\n",
    "        print(name)\n",
    "        print(seqs)\n",
    "        print(true[i])\n",
    "        assert np.array_equal(true[i], seqs), \"Sequences do not match.\"\n",
    "\n",
    "    # Clean up temporary files\n",
    "    for f in temp_dir.iterdir():\n",
    "        print(f)\n",
    "        if f.is_dir():\n",
    "            os.system(f'rm -r {f}')\n",
    "        else:\n",
    "            f.unlink()\n",
    "\n",
    "    print(\"All tests passed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_length = 20\n",
    "\n",
    "outfile = Path(sd.__file__).resolve().parent.parent / 'tests' / 'data' / 'tmp' / 'output.zarr'\n",
    "\n",
    "bed = pd.read_csv(fixed_bed_in, sep=\"\\t\", header=None)\n",
    "bed\n",
    "\n",
    "if fixed_length:\n",
    "    midpoint = (bed[1] + bed[2]) // 2\n",
    "    bed[1] = midpoint - fixed_length // 2\n",
    "    bed[2] = midpoint + fixed_length // 2\n",
    "bed\n",
    "\n",
    "fasta_sequences = read_fasta(variable_fasta_in)\n",
    "\n",
    "true_seqs = [fasta_sequences[chrom][start:end] for chrom, start, end in bed.values]\n",
    "true_seqs\n",
    "\n",
    "genome_fasta = GenomeFASTA(\n",
    "    name=\"seq\",\n",
    "    fasta=variable_fasta_in,\n",
    "    batch_size=50,\n",
    ")\n",
    "bam = BAM(\n",
    "    name=\"cov\",\n",
    "    bams=bams,\n",
    "    samples=[bam.name for bam in bams],\n",
    "    batch_size=50,\n",
    ")\n",
    "\n",
    "data = from_region_files(\n",
    "    genome_fasta, \n",
    "    bam, \n",
    "    bed=fixed_bed_in,\n",
    "    path=outfile,\n",
    "    fixed_length=20,\n",
    "    length_dim=\"_length\",\n",
    "    sequence_dim=\"_sequence\",\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "# Verify length and sequence dimensions\n",
    "if fixed_length:\n",
    "    assert data[\"seq\"].shape[1] == fixed_length, \"Length dimension is incorrect.\"\n",
    "assert data[\"seq\"].shape[0] == len(bed), \"Sequence dimension is incorrect.\"\n",
    "\n",
    "# Verify that the data is the same\n",
    "if fixed_length:\n",
    "    seqs = [''.join(row.astype(str)) for row in data[\"seq\"].values]\n",
    "else:\n",
    "    seqs = data[\"seq\"].values.astype(str)\n",
    "print(seqs)\n",
    "print(true_seqs)\n",
    "assert np.array_equal(true_seqs, seqs), \"Sequences do not match.\"\n",
    "\n",
    "# Verify that the data matches the expected coverage for all regions\n",
    "for file_index, bam_file in enumerate(bams):\n",
    "    print(f\"Testing {bam_file}\")\n",
    "    bam_name = bam_file.name\n",
    "    for region_index, (region, coverage) in enumerate(new_cov[bam_name].items()):\n",
    "        print(data['cov'][region_index].shape)\n",
    "        print(f\"Region {region}: {list(data['cov'].values[region_index, file_index])}, {coverage}\")\n",
    "        assert np.array_equal(coverage, data[\"cov\"].values[region_index, file_index]), f\"Region {region} in {bam_name} does not match.\"\n",
    "\n",
    "# Clean up temporary files\n",
    "for f in temp_dir.iterdir():\n",
    "    if f.is_dir():\n",
    "        os.system(f'rm -r {f}')\n",
    "    else:\n",
    "        f.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `read_genome_fasta`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqdata import read_genome_fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 82472.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "temp_dir = Path(out)\n",
    "temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "out = temp_dir / 'output.zarr'\n",
    "\n",
    "sdata = read_genome_fasta(\n",
    "    fasta=variable_fasta_in,\n",
    "    bed=fixed_bed_in,\n",
    "    out=out,\n",
    "    name=\"seq\",\n",
    "    fixed_length=20,\n",
    "    batch_size=50,\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "# Verify length and sequence dimensions\n",
    "fasta_sequences = read_fasta(variable_fasta_in)\n",
    "true = [fasta_sequences[chrom][start:end] for chrom, start, end in bed.values]\n",
    "\n",
    "if fixed_length:\n",
    "    assert data[\"seq\"].shape[1] == fixed_length, \"Length dimension is incorrect.\"\n",
    "assert data[\"seq\"].shape[0] == len(bed), \"Sequence dimension is incorrect.\"\n",
    "\n",
    "# Verify that the data is the same\n",
    "if fixed_length:\n",
    "    seqs = [''.join(row.astype(str)) for row in data[\"seq\"].values]\n",
    "else:\n",
    "    seqs = data[\"seq\"].values.astype(str)\n",
    "assert np.array_equal(true, seqs), \"Sequences do not match.\"\n",
    "\n",
    "# Clean up temporary files\n",
    "for f in temp_dir.iterdir():\n",
    "    if f.is_dir():\n",
    "        os.system(f'rm -r {f}')\n",
    "    else:\n",
    "        f.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `read_bam`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqdata import read_bam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 123361.88it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 14135.83it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 11027.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 11056.35it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 13862.19it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 12959.67it/s]\n"
     ]
    }
   ],
   "source": [
    "temp_dir = Path(out)\n",
    "temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "out = temp_dir / 'output.zarr'\n",
    "\n",
    "sdata = read_bam(\n",
    "    fasta=variable_fasta_in,\n",
    "    bed=fixed_bed_in,\n",
    "    bams=bams,\n",
    "    out=out,\n",
    "    seq_name=\"seq\",\n",
    "    cov_name=\"cov\",\n",
    "    samples=[b.name for b in bams],\n",
    "    fixed_length=20,\n",
    "    batch_size=50,\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "# Verify length and sequence dimensions\n",
    "fasta_sequences = read_fasta(variable_fasta_in)\n",
    "true = [fasta_sequences[chrom][start:end] for chrom, start, end in bed.values]\n",
    "\n",
    "if fixed_length:\n",
    "    assert data[\"seq\"].shape[1] == fixed_length, \"Length dimension is incorrect.\"\n",
    "assert data[\"seq\"].shape[0] == len(bed), \"Sequence dimension is incorrect.\"\n",
    "\n",
    "# Verify that the data is the same\n",
    "if fixed_length:\n",
    "    seqs = [''.join(row.astype(str)) for row in data[\"seq\"].values]\n",
    "else:\n",
    "    seqs = data[\"seq\"].values.astype(str)\n",
    "assert np.array_equal(true, seqs), \"Sequences do not match.\"\n",
    "\n",
    "# Clean up temporary files\n",
    "for f in temp_dir.iterdir():\n",
    "    if f.is_dir():\n",
    "        os.system(f'rm -r {f}')\n",
    "    else:\n",
    "        f.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `read_bigwig`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqdata import read_bigwig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['simulated1.bw',\n",
       " 'simulated2.bw',\n",
       " 'simulated3.bw',\n",
       " 'simulated4.bw',\n",
       " 'simulated5.bw']"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[b.name for b in bigwigs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 136877.05it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 16105.39it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 29360.13it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 24734.73it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 38990.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 14/14 [00:00<00:00, 26985.41it/s]\n"
     ]
    }
   ],
   "source": [
    "temp_dir = Path(out)\n",
    "temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "out = temp_dir / 'output.zarr'\n",
    "\n",
    "sdata = read_bigwig(\n",
    "    fasta=variable_fasta_in,\n",
    "    bed=fixed_bed_in,\n",
    "    bigwigs=bigwigs,\n",
    "    out=out,\n",
    "    seq_name=\"seq\",\n",
    "    cov_name=\"cov\",\n",
    "    samples=[b.name for b in bigwigs],\n",
    "    fixed_length=20,\n",
    "    batch_size=50,\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "# Verify length and sequence dimensions\n",
    "fasta_sequences = read_fasta(variable_fasta_in)\n",
    "true = [fasta_sequences[chrom][start:end] for chrom, start, end in bed.values]\n",
    "\n",
    "if fixed_length:\n",
    "    assert data[\"seq\"].shape[1] == fixed_length, \"Length dimension is incorrect.\"\n",
    "assert data[\"seq\"].shape[0] == len(bed), \"Sequence dimension is incorrect.\"\n",
    "\n",
    "# Verify that the data is the same\n",
    "if fixed_length:\n",
    "    seqs = [''.join(row.astype(str)) for row in data[\"seq\"].values]\n",
    "else:\n",
    "    seqs = data[\"seq\"].values.astype(str)\n",
    "assert np.array_equal(true, seqs), \"Sequences do not match.\"\n",
    "\n",
    "# Clean up temporary files\n",
    "for f in temp_dir.iterdir():\n",
    "    if f.is_dir():\n",
    "        os.system(f'rm -r {f}')\n",
    "    else:\n",
    "        f.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing BAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chrom: chr1, start: 10, end: 30\n",
      "20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 3, 4, 4, 4, 4, 3, 3, 3, 4, 6, 6, 6, 6, 6, 6, 7],\n",
       "      dtype=uint16)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_num = 0\n",
    "print(f\"chrom: {bed.iloc[seq_num]['chrom']}, start: {bed.iloc[seq_num]['start']}, end: {bed.iloc[seq_num]['end']}\")\n",
    "cov = bam_reader._count_depth_only(\n",
    "    f=pysam.AlignmentFile(inbam),\n",
    "    contig=bed.iloc[seq_num]['chrom'],\n",
    "    start=bed.iloc[seq_num]['start'],\n",
    "    end=bed.iloc[seq_num]['end']\n",
    ")\n",
    "print(len(cov))\n",
    "cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_read = [seq for seq in iterator]\n",
    "_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inbam = \"/cellar/users/aklie/data/datasets/SeqDatasets/K562_ATAC-seq/data/merged.bam\"\n",
    "#inbed = \"/cellar/users/aklie/data/datasets/SeqDatasets/K562_ATAC-seq/data/ENCSR868FGK_K562_ATAC-seq_peaks.bed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pysam.AlignmentFile(inbam)\n",
    "bed = pd.read_csv(inbed, sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array('L', [0, 3, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0, 0, 6, 0, 0, 6, 0, 0, 0]),\n",
       " array('L', [0, 0, 2, 0, 2, 2, 0, 0, 4, 5, 0, 0, 0, 0, 6, 0, 0, 0, 6, 6]),\n",
       " array('L', [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array('L', [4, 0, 0, 2, 0, 0, 3, 0, 0, 0, 0, 4, 0, 0, 0, 7, 0, 5, 0, 0]))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f.count_coverage(\n",
    "    contig=bed.iloc[1][0],\n",
    "    start=bed.iloc[1][1],\n",
    "    stop=bed.iloc[1][2],\n",
    "    #read_callback='nofilter',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data using the reader\n",
    "_read = [seq.decode('utf-8') for seq in iterator]\n",
    "\n",
    "# Verify that the data is the same\n",
    "assert np.array_equal(_read, true), \"GenomeFASTA reader failed to read in the correct values.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read name: read_chr1_9_19\n",
      "Reference: chr1\n",
      "Start position: 9\n",
      "Read sequence: CCGACTAACT\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_10_20\n",
      "Reference: chr1\n",
      "Start position: 10\n",
      "Read sequence: CGACTAACTG\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_14_24\n",
      "Reference: chr1\n",
      "Start position: 14\n",
      "Read sequence: TAACTGACTG\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_15_25\n",
      "Reference: chr1\n",
      "Start position: 15\n",
      "Read sequence: AACTGACTGA\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_20_30\n",
      "Reference: chr1\n",
      "Start position: 20\n",
      "Read sequence: ACTGATGATG\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_22_32\n",
      "Reference: chr1\n",
      "Start position: 22\n",
      "Read sequence: TGATGATGAT\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_23_33\n",
      "Reference: chr1\n",
      "Start position: 23\n",
      "Read sequence: GATGATGATG\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_23_33\n",
      "Reference: chr1\n",
      "Start position: 23\n",
      "Read sequence: GATGATGATG\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_9_19\n",
      "Reference: chr1\n",
      "Start position: 24\n",
      "Read sequence: ATGATGATGC\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_10_20\n",
      "Reference: chr1\n",
      "Start position: 25\n",
      "Read sequence: TGATGATGCA\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_14_24\n",
      "Reference: chr1\n",
      "Start position: 29\n",
      "Read sequence: GATGCATGCT\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_15_25\n",
      "Reference: chr1\n",
      "Start position: 30\n",
      "Read sequence: ATGCATGCTG\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_20_30\n",
      "Reference: chr1\n",
      "Start position: 35\n",
      "Read sequence: TGCTGATGCT\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_22_32\n",
      "Reference: chr1\n",
      "Start position: 37\n",
      "Read sequence: CTGATGCTGA\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_23_33\n",
      "Reference: chr1\n",
      "Start position: 38\n",
      "Read sequence: TGATGCTGAA\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_23_33\n",
      "Reference: chr1\n",
      "Start position: 38\n",
      "Read sequence: TGATGCTGAA\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_71_81\n",
      "Reference: chr1\n",
      "Start position: 71\n",
      "Read sequence: GACTGACTGT\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_72_82\n",
      "Reference: chr1\n",
      "Start position: 72\n",
      "Read sequence: ACTGACTGTA\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_74_84\n",
      "Reference: chr1\n",
      "Start position: 74\n",
      "Read sequence: TGACTGTACT\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_80_90\n",
      "Reference: chr1\n",
      "Start position: 80\n",
      "Read sequence: TACTCCTACC\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_84_94\n",
      "Reference: chr1\n",
      "Start position: 84\n",
      "Read sequence: CCTACCATGA\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_71_81\n",
      "Reference: chr1\n",
      "Start position: 86\n",
      "Read sequence: TACCATGACT\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_72_82\n",
      "Reference: chr1\n",
      "Start position: 87\n",
      "Read sequence: ACCATGACTA\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_74_84\n",
      "Reference: chr1\n",
      "Start position: 89\n",
      "Read sequence: CATGACTATC\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_92_102\n",
      "Reference: chr1\n",
      "Start position: 92\n",
      "Read sequence: GACTATCCTA\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_93_103\n",
      "Reference: chr1\n",
      "Start position: 93\n",
      "Read sequence: ACTATCCTAG\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_94_104\n",
      "Reference: chr1\n",
      "Start position: 94\n",
      "Read sequence: CTATCCTAGT\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_80_90\n",
      "Reference: chr1\n",
      "Start position: 95\n",
      "Read sequence: TATCCTAGTG\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_98_108\n",
      "Reference: chr1\n",
      "Start position: 98\n",
      "Read sequence: CCTAGTGCTG\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_84_94\n",
      "Reference: chr1\n",
      "Start position: 99\n",
      "Read sequence: CTAGTGCTGA\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_92_102\n",
      "Reference: chr1\n",
      "Start position: 107\n",
      "Read sequence: GACCTGACTG\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_93_103\n",
      "Reference: chr1\n",
      "Start position: 108\n",
      "Read sequence: ACCTGACTGA\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_94_104\n",
      "Reference: chr1\n",
      "Start position: 109\n",
      "Read sequence: CCTGACTGAT\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_98_108\n",
      "Reference: chr1\n",
      "Start position: 113\n",
      "Read sequence: ACTGATGCTG\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_134_144\n",
      "Reference: chr1\n",
      "Start position: 134\n",
      "Read sequence: ATGCACTGAC\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_135_145\n",
      "Reference: chr1\n",
      "Start position: 135\n",
      "Read sequence: TGCACTGACT\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_135_145\n",
      "Reference: chr1\n",
      "Start position: 135\n",
      "Read sequence: TGCACTGACT\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_147_157\n",
      "Reference: chr1\n",
      "Start position: 147\n",
      "Read sequence: CTCTACATGA\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_148_158\n",
      "Reference: chr1\n",
      "Start position: 148\n",
      "Read sequence: TCTACATGAC\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_134_144\n",
      "Reference: chr1\n",
      "Start position: 149\n",
      "Read sequence: CTACATGACT\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_135_145\n",
      "Reference: chr1\n",
      "Start position: 150\n",
      "Read sequence: TACATGACTG\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_135_145\n",
      "Reference: chr1\n",
      "Start position: 150\n",
      "Read sequence: TACATGACTG\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_153_163\n",
      "Reference: chr1\n",
      "Start position: 153\n",
      "Read sequence: ATGACTGACT\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_154_164\n",
      "Reference: chr1\n",
      "Start position: 154\n",
      "Read sequence: TGACTGACTC\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_155_165\n",
      "Reference: chr1\n",
      "Start position: 155\n",
      "Read sequence: GACTGACTCA\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_155_165\n",
      "Reference: chr1\n",
      "Start position: 155\n",
      "Read sequence: GACTGACTCA\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_159_169\n",
      "Reference: chr1\n",
      "Start position: 159\n",
      "Read sequence: GACTCACTCA\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_147_157\n",
      "Reference: chr1\n",
      "Start position: 162\n",
      "Read sequence: TCACTCATCT\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_148_158\n",
      "Reference: chr1\n",
      "Start position: 163\n",
      "Read sequence: CACTCATCTG\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_153_163\n",
      "Reference: chr1\n",
      "Start position: 168\n",
      "Read sequence: ATCTGACATA\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_154_164\n",
      "Reference: chr1\n",
      "Start position: 169\n",
      "Read sequence: TCTGACATAT\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_155_165\n",
      "Reference: chr1\n",
      "Start position: 170\n",
      "Read sequence: CTGACATATC\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_155_165\n",
      "Reference: chr1\n",
      "Start position: 170\n",
      "Read sequence: CTGACATATC\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_159_169\n",
      "Reference: chr1\n",
      "Start position: 174\n",
      "Read sequence: CATATCCATG\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr2_30_40\n",
      "Reference: chr2\n",
      "Start position: 30\n",
      "Read sequence: ATCTACTACT\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr2_34_44\n",
      "Reference: chr2\n",
      "Start position: 34\n",
      "Read sequence: ACTACTGCTA\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr2_42_52\n",
      "Reference: chr2\n",
      "Start position: 42\n",
      "Read sequence: TATACTCATA\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr2_42_52\n",
      "Reference: chr2\n",
      "Start position: 42\n",
      "Read sequence: TATACTCATA\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr2_44_54\n",
      "Reference: chr2\n",
      "Start position: 44\n",
      "Read sequence: TACTCATATC\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr2_30_40\n",
      "Reference: chr2\n",
      "Start position: 45\n",
      "Read sequence: ACTCATATCT\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr2_34_44\n",
      "Reference: chr2\n",
      "Start position: 49\n",
      "Read sequence: ATATCTACTA\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr2_42_52\n",
      "Reference: chr2\n",
      "Start position: 57\n",
      "Read sequence: TACTACTACT\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr2_42_52\n",
      "Reference: chr2\n",
      "Start position: 57\n",
      "Read sequence: TACTACTACT\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr2_44_54\n",
      "Reference: chr2\n",
      "Start position: 59\n",
      "Read sequence: CTACTACTCA\n",
      "CIGAR string: 10M\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "# Open the BAM file for reading\n",
    "with pysam.AlignmentFile(inbam, \"rb\") as bamfile:\n",
    "    # Iterate over each read\n",
    "    for read in bamfile.fetch():\n",
    "        print(f\"Read name: {read.query_name}\")\n",
    "        print(f\"Reference: {bamfile.get_reference_name(read.reference_id)}\")\n",
    "        print(f\"Start position: {read.reference_start}\")\n",
    "        print(f\"Read sequence: {read.query_sequence}\")\n",
    "        print(f\"CIGAR string: {read.cigarstring}\")\n",
    "        print(\"------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 eugene_tools",
   "language": "python",
   "name": "eugene_tools"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
