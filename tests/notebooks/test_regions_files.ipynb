{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GenomeFasta -- fixed length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequences_from_bed(fasta_sequences, coordinates):\n",
    "    \"\"\"\n",
    "    Retrieves sequences from a FASTA dictionary using BED coordinates.\n",
    "\n",
    "    Parameters:\n",
    "        fasta_sequences (dict): Dictionary of sequences from `read_fasta`.\n",
    "        coordinates (list): List of tuples (chromosome, start, end).\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are coordinates and values are sequences.\n",
    "    \"\"\"\n",
    "    extracted_sequences = {}\n",
    "    for chrom, start, end in coordinates:\n",
    "        if chrom in fasta_sequences:\n",
    "            sequence = fasta_sequences[chrom][start:end]  # Extract the sequence using coordinates\n",
    "            extracted_sequences[(chrom, start, end)] = sequence\n",
    "        else:\n",
    "            extracted_sequences[(chrom, start, end)] = None  # Handle missing chromosomes\n",
    "    return extracted_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/tangermeme2.fa'),\n",
       " PosixPath('/cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/tangermeme2.bed'),\n",
       " PosixPath('/cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/tmp/genomefasta_reader.zarr'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get file name\n",
    "infasta = Path(sd.__file__).resolve().parent.parent / 'tests' / 'data' / 'tangermeme2.fa'\n",
    "inbed = Path(sd.__file__).resolve().parent.parent / 'tests' / 'data' / 'tangermeme2.bed'\n",
    "outname = Path(sd.__file__).resolve().parent.parent / 'tests' / 'data' / 'tmp' / 'genomefasta_reader.zarr'\n",
    "infasta, inbed, outname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ATGCTGAACTGACTAGCACT',\n",
       " 'CTGACTGACTGCATATGCAC',\n",
       " 'GCTATACTCATATCTACTAC',\n",
       " 'ACTTACTATCATGACTGACT',\n",
       " 'CTGacggagcacATCCATCT',\n",
       " 'ACGcacaCTACTACTACTCA',\n",
       " 'CTACACTGGCACGTTACATC',\n",
       " 'CTCAGCANNNNNNNNCacat',\n",
       " 'CTCATGCTGACGCATGCTGA']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read in data with Python as true representation\n",
    "bed = pd.read_csv(inbed, sep=\"\\t\", header=None)\n",
    "coords = bed.values\n",
    "fasta = read_fasta(infasta)\n",
    "true = list(get_sequences_from_bed(fasta, coords).values())\n",
    "bed[\"strand\"] = \"+\"\n",
    "true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test instantiation of each reader class\n",
    "genomefasta_reader = GenomeFASTA(\n",
    "    name=\"seq\",\n",
    "    fasta=infasta,\n",
    "    batch_size=50,\n",
    ")\n",
    "assert isinstance(genomefasta_reader, GenomeFASTA), \"GenomeFASTA reader instantiation failed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 8515.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# Test reading in the data\n",
    "iterator = genomefasta_reader._reader(\n",
    "    bed=bed,\n",
    "    f=pysam.FastaFile(infasta)\n",
    ")\n",
    "\n",
    "# Read in the data using the reader\n",
    "_read = [seq.decode('utf-8') for seq in iterator]\n",
    "\n",
    "# Verify that the data is the same\n",
    "assert np.array_equal(_read, true), \"GenomeFASTA reader failed to read in the correct values.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 7224.64it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<zarr.hierarchy.Group '/'>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test writing to Zarr\n",
    "genomefasta_reader._write(\n",
    "    outname, \n",
    "    bed=bed,\n",
    "    fixed_length=20, \n",
    "    sequence_dim=\"_sequence\", \n",
    "    length_dim=\"_length\",\n",
    "    overwrite=True\n",
    ")\n",
    "zarr.consolidate_metadata(outname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or directory: '/cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/tmp/bam_reader.zarr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/eugene_tools/lib/python3.11/site-packages/xarray/backends/zarr.py:1612\u001b[0m, in \u001b[0;36m_get_open_params\u001b[0;34m(store, mode, synchronizer, group, consolidated, consolidate_on_close, chunk_store, storage_options, stacklevel, zarr_version, use_zarr_fill_value_as_mask, zarr_format)\u001b[0m\n",
      "\u001b[1;32m   1611\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m-> 1612\u001b[0m     zarr_group \u001b[38;5;241m=\u001b[39m \u001b[43mzarr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_consolidated\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopen_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1613\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mKeyError\u001b[39;00m):\n",
      "\u001b[1;32m   1614\u001b[0m     \u001b[38;5;66;03m# ValueError in zarr-python 3.x, KeyError in 2.x.\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/eugene_tools/lib/python3.11/site-packages/zarr/convenience.py:1360\u001b[0m, in \u001b[0;36mopen_consolidated\u001b[0;34m(store, metadata_key, mode, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1359\u001b[0m \u001b[38;5;66;03m# setup metadata store\u001b[39;00m\n",
      "\u001b[0;32m-> 1360\u001b[0m meta_store \u001b[38;5;241m=\u001b[39m \u001b[43mConsolidatedStoreClass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata_key\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1362\u001b[0m \u001b[38;5;66;03m# pass through\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/eugene_tools/lib/python3.11/site-packages/zarr/storage.py:3046\u001b[0m, in \u001b[0;36mConsolidatedMetadataStore.__init__\u001b[0;34m(self, store, metadata_key)\u001b[0m\n",
      "\u001b[1;32m   3045\u001b[0m \u001b[38;5;66;03m# retrieve consolidated metadata\u001b[39;00m\n",
      "\u001b[0;32m-> 3046\u001b[0m meta \u001b[38;5;241m=\u001b[39m json_loads(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmetadata_key\u001b[49m\u001b[43m]\u001b[49m)\n",
      "\u001b[1;32m   3048\u001b[0m \u001b[38;5;66;03m# check format of consolidated metadata\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/eugene_tools/lib/python3.11/site-packages/zarr/storage.py:1120\u001b[0m, in \u001b[0;36mDirectoryStore.__getitem__\u001b[0;34m(self, key)\u001b[0m\n",
      "\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m-> 1120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\n",
      "\u001b[0;31mKeyError\u001b[0m: '.zmetadata'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[0;31mGroupNotFoundError\u001b[0m                        Traceback (most recent call last)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/eugene_tools/lib/python3.11/site-packages/xarray/backends/zarr.py:1616\u001b[0m, in \u001b[0;36m_get_open_params\u001b[0;34m(store, mode, synchronizer, group, consolidated, consolidate_on_close, chunk_store, storage_options, stacklevel, zarr_version, use_zarr_fill_value_as_mask, zarr_format)\u001b[0m\n",
      "\u001b[1;32m   1615\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m-> 1616\u001b[0m     zarr_group \u001b[38;5;241m=\u001b[39m \u001b[43mzarr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopen_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1617\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n",
      "\u001b[1;32m   1618\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to open Zarr store with consolidated metadata, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m   1619\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut successfully read with non-consolidated metadata. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m   1630\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n",
      "\u001b[1;32m   1631\u001b[0m     )\n",
      "\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/eugene_tools/lib/python3.11/site-packages/zarr/hierarchy.py:1578\u001b[0m, in \u001b[0;36mopen_group\u001b[0;34m(store, mode, cache_attrs, synchronizer, path, chunk_store, storage_options, zarr_version, meta_array)\u001b[0m\n",
      "\u001b[1;32m   1577\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m ContainsArrayError(path)\n",
      "\u001b[0;32m-> 1578\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m GroupNotFoundError(path)\n",
      "\u001b[1;32m   1580\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\n",
      "\u001b[0;31mGroupNotFoundError\u001b[0m: group not found at path ''\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[521], line 2\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Test round-trip reading\u001b[39;00m\n",
      "\u001b[0;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43msd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_zarr\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Verify _length dimension is 20\u001b[39;00m\n",
      "\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m20\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength dimension is incorrect.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\n",
      "File \u001b[0;32m~/projects/ML4GLand/SeqData/seqdata/xarray/seqdata.py:101\u001b[0m, in \u001b[0;36mopen_zarr\u001b[0;34m(store, group, synchronizer, chunks, decode_cf, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, consolidated, overwrite_encoded_chunks, chunk_store, storage_options, decode_timedelta, use_cftime, zarr_version, **kwargs)\u001b[0m\n",
      "\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_zarr\u001b[39m(\n",
      "\u001b[1;32m     36\u001b[0m     store: PathType,\n",
      "\u001b[1;32m     37\u001b[0m     group: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m     55\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n",
      "\u001b[1;32m     56\u001b[0m ):\n",
      "\u001b[1;32m     57\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Open a SeqData object from disk.\u001b[39;00m\n",
      "\u001b[1;32m     58\u001b[0m \n",
      "\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m        SeqData object\u001b[39;00m\n",
      "\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;32m--> 101\u001b[0m     ds \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_zarr\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynchronizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronizer\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n",
      "\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_cf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_cf\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask_and_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_and_scale\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_times\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconcat_characters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcat_characters\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_coords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_coords\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrop_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_variables\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconsolidated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconsolidated\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverwrite_encoded_chunks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_encoded_chunks\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunk_store\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk_store\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_timedelta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_timedelta\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cftime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cftime\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzarr_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzarr_version\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/eugene_tools/lib/python3.11/site-packages/xarray/backends/zarr.py:1337\u001b[0m, in \u001b[0;36mopen_zarr\u001b[0;34m(store, group, synchronizer, chunks, decode_cf, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, consolidated, overwrite_encoded_chunks, chunk_store, storage_options, decode_timedelta, use_cftime, zarr_version, zarr_format, use_zarr_fill_value_as_mask, chunked_array_type, from_array_kwargs, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1322\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n",
      "\u001b[1;32m   1323\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopen_zarr() got unexpected keyword arguments \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(kwargs\u001b[38;5;241m.\u001b[39mkeys())\n",
      "\u001b[1;32m   1324\u001b[0m     )\n",
      "\u001b[1;32m   1326\u001b[0m backend_kwargs \u001b[38;5;241m=\u001b[39m {\n",
      "\u001b[1;32m   1327\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msynchronizer\u001b[39m\u001b[38;5;124m\"\u001b[39m: synchronizer,\n",
      "\u001b[1;32m   1328\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconsolidated\u001b[39m\u001b[38;5;124m\"\u001b[39m: consolidated,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m   1334\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzarr_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: zarr_format,\n",
      "\u001b[1;32m   1335\u001b[0m }\n",
      "\u001b[0;32m-> 1337\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m   1338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_cf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_cf\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask_and_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_and_scale\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_times\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconcat_characters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcat_characters\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_coords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_coords\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzarr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_variables\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked_array_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked_array_type\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrom_array_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_array_kwargs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackend_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend_kwargs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_timedelta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_timedelta\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1352\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cftime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cftime\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mzarr_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzarr_version\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1354\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_zarr_fill_value_as_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_zarr_fill_value_as_mask\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/eugene_tools/lib/python3.11/site-packages/xarray/backends/api.py:671\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    659\u001b[0m decoders \u001b[38;5;241m=\u001b[39m _resolve_decoders_kwargs(\n",
      "\u001b[1;32m    660\u001b[0m     decode_cf,\n",
      "\u001b[1;32m    661\u001b[0m     open_backend_dataset_parameters\u001b[38;5;241m=\u001b[39mbackend\u001b[38;5;241m.\u001b[39mopen_dataset_parameters,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    667\u001b[0m     decode_coords\u001b[38;5;241m=\u001b[39mdecode_coords,\n",
      "\u001b[1;32m    668\u001b[0m )\n",
      "\u001b[1;32m    670\u001b[0m overwrite_encoded_chunks \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite_encoded_chunks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;32m--> 671\u001b[0m backend_ds \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_variables\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdecoders\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    676\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    677\u001b[0m ds \u001b[38;5;241m=\u001b[39m _dataset_from_backend_dataset(\n",
      "\u001b[1;32m    678\u001b[0m     backend_ds,\n",
      "\u001b[1;32m    679\u001b[0m     filename_or_obj,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    689\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n",
      "\u001b[1;32m    690\u001b[0m )\n",
      "\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/eugene_tools/lib/python3.11/site-packages/xarray/backends/zarr.py:1410\u001b[0m, in \u001b[0;36mZarrBackendEntrypoint.open_dataset\u001b[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, group, mode, synchronizer, consolidated, chunk_store, storage_options, stacklevel, zarr_version, zarr_format, store, engine, use_zarr_fill_value_as_mask)\u001b[0m\n",
      "\u001b[1;32m   1408\u001b[0m filename_or_obj \u001b[38;5;241m=\u001b[39m _normalize_path(filename_or_obj)\n",
      "\u001b[1;32m   1409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m store:\n",
      "\u001b[0;32m-> 1410\u001b[0m     store \u001b[38;5;241m=\u001b[39m \u001b[43mZarrStore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_group\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m   1411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1414\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynchronizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronizer\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconsolidated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconsolidated\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconsolidate_on_close\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunk_store\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk_store\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1419\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstacklevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstacklevel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzarr_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzarr_version\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1421\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_zarr_fill_value_as_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzarr_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzarr_format\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   1423\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1425\u001b[0m store_entrypoint \u001b[38;5;241m=\u001b[39m StoreBackendEntrypoint()\n",
      "\u001b[1;32m   1426\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m close_on_error(store):\n",
      "\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/eugene_tools/lib/python3.11/site-packages/xarray/backends/zarr.py:636\u001b[0m, in \u001b[0;36mZarrStore.open_group\u001b[0;34m(cls, store, mode, synchronizer, group, consolidated, consolidate_on_close, chunk_store, storage_options, append_dim, write_region, safe_chunks, stacklevel, zarr_version, zarr_format, use_zarr_fill_value_as_mask, write_empty)\u001b[0m\n",
      "\u001b[1;32m    611\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n",
      "\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_group\u001b[39m(\n",
      "\u001b[1;32m    613\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    629\u001b[0m     write_empty: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "\u001b[1;32m    630\u001b[0m ):\n",
      "\u001b[1;32m    631\u001b[0m     (\n",
      "\u001b[1;32m    632\u001b[0m         zarr_group,\n",
      "\u001b[1;32m    633\u001b[0m         consolidate_on_close,\n",
      "\u001b[1;32m    634\u001b[0m         close_store_on_close,\n",
      "\u001b[1;32m    635\u001b[0m         use_zarr_fill_value_as_mask,\n",
      "\u001b[0;32m--> 636\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[43m_get_open_params\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    637\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    638\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    639\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynchronizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronizer\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    640\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    641\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconsolidated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconsolidated\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    642\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconsolidate_on_close\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconsolidate_on_close\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    643\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunk_store\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk_store\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstacklevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstacklevel\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    646\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzarr_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzarr_version\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    647\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_zarr_fill_value_as_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_zarr_fill_value_as_mask\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    648\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzarr_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzarr_format\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    651\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\n",
      "\u001b[1;32m    652\u001b[0m         zarr_group,\n",
      "\u001b[1;32m    653\u001b[0m         mode,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    660\u001b[0m         use_zarr_fill_value_as_mask,\n",
      "\u001b[1;32m    661\u001b[0m     )\n",
      "\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/eugene_tools/lib/python3.11/site-packages/xarray/backends/zarr.py:1633\u001b[0m, in \u001b[0;36m_get_open_params\u001b[0;34m(store, mode, synchronizer, group, consolidated, consolidate_on_close, chunk_store, storage_options, stacklevel, zarr_version, use_zarr_fill_value_as_mask, zarr_format)\u001b[0m\n",
      "\u001b[1;32m   1617\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n",
      "\u001b[1;32m   1618\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to open Zarr store with consolidated metadata, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m   1619\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut successfully read with non-consolidated metadata. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m   1630\u001b[0m                 stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n",
      "\u001b[1;32m   1631\u001b[0m             )\n",
      "\u001b[1;32m   1632\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m missing_exc \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[0;32m-> 1633\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n",
      "\u001b[1;32m   1634\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstore\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m   1635\u001b[0m             ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[1;32m   1636\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m consolidated:\n",
      "\u001b[1;32m   1637\u001b[0m     \u001b[38;5;66;03m# TODO: an option to pass the metadata_key keyword\u001b[39;00m\n",
      "\u001b[1;32m   1638\u001b[0m     zarr_group \u001b[38;5;241m=\u001b[39m zarr\u001b[38;5;241m.\u001b[39mopen_consolidated(store, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mopen_kwargs)\n",
      "\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or directory: '/cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/tmp/bam_reader.zarr'"
     ]
    }
   ],
   "source": [
    "# Test round-trip reading\n",
    "data = sd.open_zarr(outname)\n",
    "\n",
    "# Verify _length dimension is 20\n",
    "assert data[\"seq\"].shape[1] == 20, \"Length dimension is incorrect.\"\n",
    "\n",
    "# Verify _sequence dimension is 9\n",
    "assert data[\"seq\"].shape[0] == 9, \"Sequence dimension is incorrect.\"\n",
    "\n",
    "# Verify that the data is the same\n",
    "seqs = [''.join(row.astype(str)) for row in data[\"seq\"].values]\n",
    "assert np.array_equal(true, seqs), \"Sequences do not match.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/tangermeme.bam'),\n",
       " PosixPath('/cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/tangermeme.bed'),\n",
       " PosixPath('/cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/tmp/bam_reader.zarr'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get file name\n",
    "infasta = Path(sd.__file__).resolve().parent.parent / 'tests' / 'data' / 'tangermeme.fa'\n",
    "inbam = Path(sd.__file__).resolve().parent.parent / 'tests' / 'data' / 'tangermeme.bam'\n",
    "inbed = Path(sd.__file__).resolve().parent.parent / 'tests' / 'data' / 'tangermeme.bed'\n",
    "outname = Path(sd.__file__).resolve().parent.parent / 'tests' / 'data' / 'tmp' / 'bam_reader.zarr'\n",
    "inbam, inbed, outname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True coverage arrays by region:\n",
      "chr1:10-30: [3, 3, 3, 3, 3, 4, 3, 3, 4, 4, 4, 5, 5, 4, 5, 4, 4, 4, 5, 4]\n",
      "chr1:80-100: [5, 5, 4, 4, 4, 4, 5, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 5, 5, 5]\n",
      "chr1:140-160: [1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2]\n",
      "chr2:25-55: [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 3, 4, 4, 3, 4, 4, 4, 4, 5, 6]\n",
      "chr2:35-65: [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 3, 4, 4, 3, 4, 4, 4, 4, 5, 6, 6, 5, 4, 4, 3, 4, 6, 8, 7, 7]\n"
     ]
    }
   ],
   "source": [
    "# Open your reference FASTA file\n",
    "fasta = pysam.FastaFile(infasta)\n",
    "bed = pd.read_csv(inbed, sep='\\t', header=None, names=['chrom', 'start', 'end'])\n",
    "\n",
    "# Parameters\n",
    "read_len = 10\n",
    "read_sep = 5  # Fixed separation between read1 and read2\n",
    "max_reads = 10\n",
    "\n",
    "# Dictionary to store true coverage for each chromosome\n",
    "true_coverage_arrays = {}\n",
    "\n",
    "# Open BAM file for writing\n",
    "with pysam.AlignmentFile(inbam, 'wb',\n",
    "                         reference_names=fasta.references,\n",
    "                         reference_lengths=fasta.lengths) as bamfile:\n",
    "    # For each region in the BED file\n",
    "    for _, region in bed.iterrows():\n",
    "        chrom = region['chrom']\n",
    "        start = region['start']\n",
    "        end = region['end']\n",
    "        \n",
    "        # Initialize true coverage array for this chromosome if not already\n",
    "        if chrom not in true_coverage_arrays:\n",
    "            true_coverage_arrays[chrom] = np.zeros(fasta.get_reference_length(chrom), dtype=int)\n",
    "        \n",
    "        # Generate read pairs overlapping the region\n",
    "        num_reads = random.randint(1, max_reads)  # Random number of read pairs\n",
    "        for _ in range(num_reads):\n",
    "            # Randomly select starting position for read1, allowing partial overlap with the BED region\n",
    "            read1_start = random.randint(max(0, start - read_len), min(end, fasta.get_reference_length(chrom) - read_len))\n",
    "            read2_start = read1_start + read_len + read_sep\n",
    "            \n",
    "            # Fetch sequences\n",
    "            read1_seq = fasta.fetch(chrom, read1_start, read1_start + read_len)\n",
    "            read2_seq = fasta.fetch(chrom, read2_start, read2_start + read_len)\n",
    "            \n",
    "            # Skip incomplete sequences\n",
    "            if len(read1_seq) < read_len or len(read2_seq) < read_len:\n",
    "                continue\n",
    "            \n",
    "            # Check if the read pair overlaps the region\n",
    "            read1_end = read1_start + read_len\n",
    "            read2_end = read2_start + read_len\n",
    "            if (read1_start < end and read1_end > start) or (read2_start < end and read2_end > start):\n",
    "                # Update true coverage for read1\n",
    "                true_coverage_arrays[chrom][read1_start:read1_start + read_len] += 1\n",
    "                \n",
    "                # Update true coverage for read2\n",
    "                true_coverage_arrays[chrom][read2_start:read2_start + read_len] += 1\n",
    "                \n",
    "                # Create read1\n",
    "                read1 = pysam.AlignedSegment()\n",
    "                read1.query_name = f\"read_{chrom}_{read1_start}_{read1_start + read_len}\"\n",
    "                read1.query_sequence = read1_seq\n",
    "                read1.flag = 99  # Proper pair, first in pair\n",
    "                read1.reference_id = bamfile.get_tid(chrom)\n",
    "                read1.reference_start = read1_start\n",
    "                read1.mapping_quality = 60\n",
    "                read1.cigar = [(0, len(read1_seq))]\n",
    "                read1.next_reference_id = bamfile.get_tid(chrom)\n",
    "                read1.next_reference_start = read2_start\n",
    "                read1.template_length = read2_start + read_len - read1_start\n",
    "                read1.query_qualities = pysam.qualitystring_to_array(\"I\" * len(read1_seq))\n",
    "                \n",
    "                # Create read2\n",
    "                read2 = pysam.AlignedSegment()\n",
    "                read2.query_name = read1.query_name\n",
    "                read2.query_sequence = read2_seq\n",
    "                read2.flag = 147  # Proper pair, second in pair\n",
    "                read2.reference_id = bamfile.get_tid(chrom)\n",
    "                read2.reference_start = read2_start\n",
    "                read2.mapping_quality = 60\n",
    "                read2.cigar = [(0, len(read2_seq))]\n",
    "                read2.next_reference_id = bamfile.get_tid(chrom)\n",
    "                read2.next_reference_start = read1_start\n",
    "                read2.template_length = -(read2_start + read_len - read1_start)\n",
    "                read2.query_qualities = pysam.qualitystring_to_array(\"I\" * len(read2_seq))\n",
    "                \n",
    "                # Write reads to BAM file\n",
    "                bamfile.write(read1)\n",
    "                bamfile.write(read2)\n",
    "\n",
    "# Extract coverage arrays for each BED region\n",
    "coverage_by_region = {}\n",
    "for _, region in bed.iterrows():\n",
    "    chrom, start, end = region['chrom'], region['start'], region['end']\n",
    "    coverage_by_region[f\"{chrom}:{start}-{end}\"] = true_coverage_arrays[chrom][start:end]\n",
    "\n",
    "print(\"True coverage arrays by region:\")\n",
    "for region, coverage in coverage_by_region.items():\n",
    "    print(f\"{region}: {list(coverage)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sort the BAM file\n",
    "pysam.sort(\"-o\", str(inbam.with_suffix(\".sorted.bam\")), str(inbam))\n",
    "\n",
    "# Index the BAM file\n",
    "pysam.index(str(inbam.with_suffix(\".sorted.bam\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update name to include sorted\n",
    "inbam = inbam.with_suffix(\".sorted.bam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "bam_reader = BAM(\n",
    "    name=\"cov\",\n",
    "    bams=inbam,\n",
    "    samples=\"tangermeme\",\n",
    "    batch_size=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 2558.75it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 2558.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# Test reading in the data\n",
    "iterator = bam_reader._reader(\n",
    "    bed=bed,\n",
    "    f=pysam.AlignmentFile(inbam)\n",
    ")\n",
    "\n",
    "# Read in the data using the reader\n",
    "_read = [list(seq) for seq in iterator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region chr1:10-30: [3, 3, 3, 3, 3, 4, 3, 3, 4, 4, 4, 5, 5, 4, 5, 4, 4, 4, 5, 4], [3 3 3 3 3 4 3 3 4 4 4 5 5 4 5 4 4 4 5 4]\n",
      "Region chr1:80-100: [5, 5, 4, 4, 4, 4, 5, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 5, 5, 5], [5 5 4 4 4 4 5 6 6 6 6 6 7 7 7 7 7 5 5 5]\n",
      "Region chr1:140-160: [1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2], [1 1 1 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 2 2]\n",
      "Region chr2:25-55: [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 3, 4, 4, 3, 4, 4, 4, 4, 5, 6], [1 1 1 1 1 1 1 0 0 0 0 0 1 2 2 2 2 2 2 2 3 4 4 3 4 4 4 4 5 6]\n",
      "Region chr2:35-65: [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 3, 4, 4, 3, 4, 4, 4, 4, 5, 6, 6, 5, 4, 4, 3, 4, 6, 8, 7, 7], [0 0 1 2 2 2 2 2 2 2 3 4 4 3 4 4 4 4 5 6 6 5 4 4 3 4 6 8 7 7]\n"
     ]
    }
   ],
   "source": [
    "# Verify that the data is the same\n",
    "for i, (region, coverage) in enumerate(coverage_by_region.items()):\n",
    "    print(f\"Region {region}: {_read[i]}, {coverage}\")\n",
    "    assert np.array_equal(coverage, _read[i]), f\"Region {region} does not match.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 3187.16it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<zarr.hierarchy.Group '/'>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test writing to Zarr\n",
    "bed[\"strand\"] = \"+\"\n",
    "bam_reader._write(\n",
    "    outname, \n",
    "    bed=bed,\n",
    "    fixed_length=False, \n",
    "    sequence_dim=\"_sequence\", \n",
    "    overwrite=True\n",
    ")\n",
    "zarr.consolidate_metadata(outname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test round-trip reading\n",
    "data = sd.open_zarr(outname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region chr1:10-30: [3, 3, 3, 3, 3, 4, 3, 3, 4, 4, 4, 5, 5, 4, 5, 4, 4, 4, 5, 4], [3 3 3 3 3 4 3 3 4 4 4 5 5 4 5 4 4 4 5 4]\n",
      "Region chr1:80-100: [5, 5, 4, 4, 4, 4, 5, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 5, 5, 5], [5 5 4 4 4 4 5 6 6 6 6 6 7 7 7 7 7 5 5 5]\n",
      "Region chr1:140-160: [1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2], [1 1 1 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 2 2]\n",
      "Region chr2:25-55: [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 3, 4, 4, 3, 4, 4, 4, 4, 5, 6], [1 1 1 1 1 1 1 0 0 0 0 0 1 2 2 2 2 2 2 2 3 4 4 3 4 4 4 4 5 6]\n",
      "Region chr2:35-65: [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 3, 4, 4, 3, 4, 4, 4, 4, 5, 6, 6, 5, 4, 4, 3, 4, 6, 8, 7, 7], [0 0 1 2 2 2 2 2 2 2 3 4 4 3 4 4 4 4 5 6 6 5 4 4 3 4 6 8 7 7]\n"
     ]
    }
   ],
   "source": [
    "# Verify that the data is the same\n",
    "for i, (region, coverage) in enumerate(coverage_by_region.items()):\n",
    "    print(f\"Region {region}: {list(data['cov'][i].values[0])}, {coverage}\")\n",
    "    assert np.array_equal(coverage, data[\"cov\"][i].values[0]), f\"Region {region} does not match.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 3, 4, 4, 3, 4, 4, 4, 4, 5, 6, 6, 5,\n",
       "        4, 4, 3, 4, 6, 8, 7, 7]),\n",
       " [3, 3, 3, 3, 3, 4, 3, 3, 4, 4, 4, 5, 5, 4, 5, 4, 4, 4, 5, 4])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coverage, _read[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chrom: chr1, start: 10, end: 30\n",
      "20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 3, 4, 4, 4, 4, 3, 3, 3, 4, 6, 6, 6, 6, 6, 6, 7],\n",
       "      dtype=uint16)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_num = 0\n",
    "print(f\"chrom: {bed.iloc[seq_num]['chrom']}, start: {bed.iloc[seq_num]['start']}, end: {bed.iloc[seq_num]['end']}\")\n",
    "cov = bam_reader._count_depth_only(\n",
    "    f=pysam.AlignmentFile(inbam),\n",
    "    contig=bed.iloc[seq_num]['chrom'],\n",
    "    start=bed.iloc[seq_num]['start'],\n",
    "    end=bed.iloc[seq_num]['end']\n",
    ")\n",
    "print(len(cov))\n",
    "cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_read = [seq for seq in iterator]\n",
    "_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inbam = \"/cellar/users/aklie/data/datasets/SeqDatasets/K562_ATAC-seq/data/merged.bam\"\n",
    "#inbed = \"/cellar/users/aklie/data/datasets/SeqDatasets/K562_ATAC-seq/data/ENCSR868FGK_K562_ATAC-seq_peaks.bed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pysam.AlignmentFile(inbam)\n",
    "bed = pd.read_csv(inbed, sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array('L', [0, 3, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0, 0, 6, 0, 0, 6, 0, 0, 0]),\n",
       " array('L', [0, 0, 2, 0, 2, 2, 0, 0, 4, 5, 0, 0, 0, 0, 6, 0, 0, 0, 6, 6]),\n",
       " array('L', [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array('L', [4, 0, 0, 2, 0, 0, 3, 0, 0, 0, 0, 4, 0, 0, 0, 7, 0, 5, 0, 0]))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f.count_coverage(\n",
    "    contig=bed.iloc[1][0],\n",
    "    start=bed.iloc[1][1],\n",
    "    stop=bed.iloc[1][2],\n",
    "    #read_callback='nofilter',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data using the reader\n",
    "_read = [seq.decode('utf-8') for seq in iterator]\n",
    "\n",
    "# Verify that the data is the same\n",
    "assert np.array_equal(_read, true), \"GenomeFASTA reader failed to read in the correct values.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read name: read_chr1_9_19\n",
      "Reference: chr1\n",
      "Start position: 9\n",
      "Read sequence: CCGACTAACT\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_10_20\n",
      "Reference: chr1\n",
      "Start position: 10\n",
      "Read sequence: CGACTAACTG\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_14_24\n",
      "Reference: chr1\n",
      "Start position: 14\n",
      "Read sequence: TAACTGACTG\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_15_25\n",
      "Reference: chr1\n",
      "Start position: 15\n",
      "Read sequence: AACTGACTGA\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_20_30\n",
      "Reference: chr1\n",
      "Start position: 20\n",
      "Read sequence: ACTGATGATG\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_22_32\n",
      "Reference: chr1\n",
      "Start position: 22\n",
      "Read sequence: TGATGATGAT\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_23_33\n",
      "Reference: chr1\n",
      "Start position: 23\n",
      "Read sequence: GATGATGATG\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_23_33\n",
      "Reference: chr1\n",
      "Start position: 23\n",
      "Read sequence: GATGATGATG\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_9_19\n",
      "Reference: chr1\n",
      "Start position: 24\n",
      "Read sequence: ATGATGATGC\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_10_20\n",
      "Reference: chr1\n",
      "Start position: 25\n",
      "Read sequence: TGATGATGCA\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_14_24\n",
      "Reference: chr1\n",
      "Start position: 29\n",
      "Read sequence: GATGCATGCT\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_15_25\n",
      "Reference: chr1\n",
      "Start position: 30\n",
      "Read sequence: ATGCATGCTG\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_20_30\n",
      "Reference: chr1\n",
      "Start position: 35\n",
      "Read sequence: TGCTGATGCT\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_22_32\n",
      "Reference: chr1\n",
      "Start position: 37\n",
      "Read sequence: CTGATGCTGA\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_23_33\n",
      "Reference: chr1\n",
      "Start position: 38\n",
      "Read sequence: TGATGCTGAA\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_23_33\n",
      "Reference: chr1\n",
      "Start position: 38\n",
      "Read sequence: TGATGCTGAA\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_71_81\n",
      "Reference: chr1\n",
      "Start position: 71\n",
      "Read sequence: GACTGACTGT\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_72_82\n",
      "Reference: chr1\n",
      "Start position: 72\n",
      "Read sequence: ACTGACTGTA\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_74_84\n",
      "Reference: chr1\n",
      "Start position: 74\n",
      "Read sequence: TGACTGTACT\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_80_90\n",
      "Reference: chr1\n",
      "Start position: 80\n",
      "Read sequence: TACTCCTACC\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_84_94\n",
      "Reference: chr1\n",
      "Start position: 84\n",
      "Read sequence: CCTACCATGA\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_71_81\n",
      "Reference: chr1\n",
      "Start position: 86\n",
      "Read sequence: TACCATGACT\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_72_82\n",
      "Reference: chr1\n",
      "Start position: 87\n",
      "Read sequence: ACCATGACTA\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_74_84\n",
      "Reference: chr1\n",
      "Start position: 89\n",
      "Read sequence: CATGACTATC\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_92_102\n",
      "Reference: chr1\n",
      "Start position: 92\n",
      "Read sequence: GACTATCCTA\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_93_103\n",
      "Reference: chr1\n",
      "Start position: 93\n",
      "Read sequence: ACTATCCTAG\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_94_104\n",
      "Reference: chr1\n",
      "Start position: 94\n",
      "Read sequence: CTATCCTAGT\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_80_90\n",
      "Reference: chr1\n",
      "Start position: 95\n",
      "Read sequence: TATCCTAGTG\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_98_108\n",
      "Reference: chr1\n",
      "Start position: 98\n",
      "Read sequence: CCTAGTGCTG\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_84_94\n",
      "Reference: chr1\n",
      "Start position: 99\n",
      "Read sequence: CTAGTGCTGA\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_92_102\n",
      "Reference: chr1\n",
      "Start position: 107\n",
      "Read sequence: GACCTGACTG\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_93_103\n",
      "Reference: chr1\n",
      "Start position: 108\n",
      "Read sequence: ACCTGACTGA\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_94_104\n",
      "Reference: chr1\n",
      "Start position: 109\n",
      "Read sequence: CCTGACTGAT\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_98_108\n",
      "Reference: chr1\n",
      "Start position: 113\n",
      "Read sequence: ACTGATGCTG\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_134_144\n",
      "Reference: chr1\n",
      "Start position: 134\n",
      "Read sequence: ATGCACTGAC\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_135_145\n",
      "Reference: chr1\n",
      "Start position: 135\n",
      "Read sequence: TGCACTGACT\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_135_145\n",
      "Reference: chr1\n",
      "Start position: 135\n",
      "Read sequence: TGCACTGACT\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_147_157\n",
      "Reference: chr1\n",
      "Start position: 147\n",
      "Read sequence: CTCTACATGA\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_148_158\n",
      "Reference: chr1\n",
      "Start position: 148\n",
      "Read sequence: TCTACATGAC\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_134_144\n",
      "Reference: chr1\n",
      "Start position: 149\n",
      "Read sequence: CTACATGACT\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_135_145\n",
      "Reference: chr1\n",
      "Start position: 150\n",
      "Read sequence: TACATGACTG\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_135_145\n",
      "Reference: chr1\n",
      "Start position: 150\n",
      "Read sequence: TACATGACTG\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_153_163\n",
      "Reference: chr1\n",
      "Start position: 153\n",
      "Read sequence: ATGACTGACT\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_154_164\n",
      "Reference: chr1\n",
      "Start position: 154\n",
      "Read sequence: TGACTGACTC\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_155_165\n",
      "Reference: chr1\n",
      "Start position: 155\n",
      "Read sequence: GACTGACTCA\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_155_165\n",
      "Reference: chr1\n",
      "Start position: 155\n",
      "Read sequence: GACTGACTCA\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_159_169\n",
      "Reference: chr1\n",
      "Start position: 159\n",
      "Read sequence: GACTCACTCA\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_147_157\n",
      "Reference: chr1\n",
      "Start position: 162\n",
      "Read sequence: TCACTCATCT\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_148_158\n",
      "Reference: chr1\n",
      "Start position: 163\n",
      "Read sequence: CACTCATCTG\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_153_163\n",
      "Reference: chr1\n",
      "Start position: 168\n",
      "Read sequence: ATCTGACATA\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_154_164\n",
      "Reference: chr1\n",
      "Start position: 169\n",
      "Read sequence: TCTGACATAT\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_155_165\n",
      "Reference: chr1\n",
      "Start position: 170\n",
      "Read sequence: CTGACATATC\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_155_165\n",
      "Reference: chr1\n",
      "Start position: 170\n",
      "Read sequence: CTGACATATC\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr1_159_169\n",
      "Reference: chr1\n",
      "Start position: 174\n",
      "Read sequence: CATATCCATG\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr2_30_40\n",
      "Reference: chr2\n",
      "Start position: 30\n",
      "Read sequence: ATCTACTACT\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr2_34_44\n",
      "Reference: chr2\n",
      "Start position: 34\n",
      "Read sequence: ACTACTGCTA\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr2_42_52\n",
      "Reference: chr2\n",
      "Start position: 42\n",
      "Read sequence: TATACTCATA\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr2_42_52\n",
      "Reference: chr2\n",
      "Start position: 42\n",
      "Read sequence: TATACTCATA\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr2_44_54\n",
      "Reference: chr2\n",
      "Start position: 44\n",
      "Read sequence: TACTCATATC\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr2_30_40\n",
      "Reference: chr2\n",
      "Start position: 45\n",
      "Read sequence: ACTCATATCT\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr2_34_44\n",
      "Reference: chr2\n",
      "Start position: 49\n",
      "Read sequence: ATATCTACTA\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr2_42_52\n",
      "Reference: chr2\n",
      "Start position: 57\n",
      "Read sequence: TACTACTACT\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr2_42_52\n",
      "Reference: chr2\n",
      "Start position: 57\n",
      "Read sequence: TACTACTACT\n",
      "CIGAR string: 10M\n",
      "------\n",
      "Read name: read_chr2_44_54\n",
      "Reference: chr2\n",
      "Start position: 59\n",
      "Read sequence: CTACTACTCA\n",
      "CIGAR string: 10M\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "# Open the BAM file for reading\n",
    "with pysam.AlignmentFile(inbam, \"rb\") as bamfile:\n",
    "    # Iterate over each read\n",
    "    for read in bamfile.fetch():\n",
    "        print(f\"Read name: {read.query_name}\")\n",
    "        print(f\"Reference: {bamfile.get_reference_name(read.reference_id)}\")\n",
    "        print(f\"Start position: {read.reference_start}\")\n",
    "        print(f\"Read sequence: {read.query_sequence}\")\n",
    "        print(f\"CIGAR string: {read.cigarstring}\")\n",
    "        print(\"------\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
