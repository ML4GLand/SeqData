{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Generate sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zarr\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from seqdata import Table, FlatFASTA, GenomeFASTA, BigWig, BAM\n",
    "import seqdata as sd\n",
    "import xarray as xr\n",
    "import pysam\n",
    "import random\n",
    "import pyBigWig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If seqpro is not installed, pip install it\n",
    "try:\n",
    "    import seqpro as sp\n",
    "except ImportError:\n",
    "    !pip install seqpro\n",
    "    import seqpro as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cellar/users/aklie/projects/ML4GLand/SeqData/tests/data\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path(sd.__file__).resolve().parent.parent / 'tests' / 'data'\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a numpy array of sequences to a FASTA file, if names is None, then the sequences are named chr1, chr2, etc.\n",
    "def write_fasta(arr, names=None, path='test.fasta', max_per_line=60):\n",
    "    if names is None:\n",
    "        names = [f'chr{i+1}' for i in range(arr.shape[0])]\n",
    "    with open(path, 'w') as f:\n",
    "        for name, seq in zip(names, arr):\n",
    "            f.write(f'>{name}\\n')\n",
    "            for i in range(0, len(seq), max_per_line):\n",
    "                f.write(seq[i:i+max_per_line] + '\\n')\n",
    "            f.write('\\n')\n",
    "    return path    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random 7 \"chromosomes\" (chr1, chr2, ..., chr7) of variable lengths\n",
    "seq_lens = [120, 400, 110, 150, 300, 100, 200]\n",
    "seqs = [''.join(sp.random_seqs((1, l), sp.DNA)[0].astype(str)) for l in seq_lens]\n",
    "names = [f'chr{i+1}' for i in range(7)]\n",
    "seq_dict = {name: seq for name, seq in zip(names, seqs)}\n",
    "\n",
    "# For chr2, make 50 random basepairs lower case\n",
    "indexes = np.random.choice(range(len(seqs[1])), 50)\n",
    "seqs[1] = ''.join([seqs[1][i].lower() if i in indexes else seqs[1][i] for i in range(len(seqs[1]))])\n",
    "\n",
    "# For chr 6, make random basepairs N\n",
    "#indexes = np.random.choice(range(len(seqs[5])), 80)\n",
    "#seqs[5] = ''.join(['N' if i in indexes else seqs[5][i] for i in range(len(seqs[5]))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fastas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `variable.fa`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as a fasta file called variable.fa\n",
    "write_fasta(seqs, names=names, path=data_dir / 'variable.fa')\n",
    "\n",
    "# Index it with pysam\n",
    "pysam.faidx(str(Path(data_dir) / 'variable.fa'))\n",
    "\n",
    "# Write variable.chrom.sizes\n",
    "with open(data_dir / 'variable.chrom.sizes', 'w') as f:\n",
    "    for i, l in enumerate(seq_lens):\n",
    "        f.write(f'chr{i+1}\\t{l}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `fixed.fa`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the first 80bp of each sequence\n",
    "fixed_seqs = [seq[:80] for seq in seqs]\n",
    "\n",
    "# Save as a fasta file called fixed.fa\n",
    "write_fasta(fixed_seqs, names=names, path=data_dir / 'fixed.fa')\n",
    "\n",
    "# Index it with pysam\n",
    "pysam.faidx(str(Path(data_dir) / 'fixed.fa'))\n",
    "\n",
    "# Write fixed.chrom.sizes\n",
    "with open(data_dir / 'fixed.chrom.sizes', 'w') as f:\n",
    "    for i, l in enumerate(seq_lens):\n",
    "        f.write(f'chr{i+1}\\t{l}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BEDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `variable.bed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_regions(sequences, num_regions=2, min_len=20, max_len=30):\n",
    "    regions = []\n",
    "    \n",
    "    for chrom, seq in sequences.items():\n",
    "        seq_len = len(seq)\n",
    "        selected_regions = []\n",
    "        \n",
    "        for _ in range(num_regions):\n",
    "            while True:\n",
    "                # Generate random length and start position\n",
    "                region_length = random.randint(min_len, max_len)\n",
    "                start = random.randint(0, seq_len - region_length)\n",
    "                end = start + region_length\n",
    "                \n",
    "                # Ensure no overlap with previous regions\n",
    "                if all(end <= r[1] or start >= r[2] for r in selected_regions):\n",
    "                    selected_regions.append((chrom, start, end))\n",
    "                    break\n",
    "        \n",
    "        regions.extend(selected_regions)\n",
    "    \n",
    "    return regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 2 random intervals on each chromosome from variable.fa using start and end coordinates\n",
    "regions = generate_regions(seq_dict)\n",
    "\n",
    "# Save as a tsv file called variable.bed with no header\n",
    "df = pd.DataFrame({'chrom': [r[0] for r in regions], 'start': [r[1] for r in regions], 'end': [r[2] for r in regions]})\n",
    "df.sort_values(['chrom', 'start']).to_csv(data_dir / 'variable.bed', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `fixed.bed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as a tsv file called fixed.bed with no header\n",
    "fixed_df = pd.DataFrame({'chrom': df['chrom'], 'start': df['start'], 'end': df['start'] + 20})\n",
    "fixed_df.sort_values(['chrom', 'start']).to_csv(data_dir / 'fixed.bed', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BAMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/variable.fa'),\n",
       " PosixPath('/cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/variable.bed'))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get file name\n",
    "infasta = Path(sd.__file__).resolve().parent.parent / 'tests' / 'data' / 'variable.fa'\n",
    "inbed = Path(sd.__file__).resolve().parent.parent / 'tests' / 'data' / 'variable.bed'\n",
    "infasta, inbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_bam(\n",
    "    infasta: Path,\n",
    "    inbed: Path,\n",
    "    inbam: Path,\n",
    "    read_len: int = 10,\n",
    "    read_sep: int = 5,\n",
    "    max_reads: int = 10,\n",
    "    seed: int = 0,\n",
    "):\n",
    "    # Open your reference FASTA file\n",
    "    fasta = pysam.FastaFile(infasta)\n",
    "    bed = pd.read_csv(inbed, sep='\\t', header=None, names=['chrom', 'start', 'end'])\n",
    "\n",
    "    # Parameters\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Dictionary to store true coverage for each chromosome\n",
    "    true_coverage_arrays = {}\n",
    "\n",
    "    # Open BAM file for writing\n",
    "    with pysam.AlignmentFile(inbam, 'wb',\n",
    "                             reference_names=fasta.references,\n",
    "                             reference_lengths=fasta.lengths) as bamfile:\n",
    "        # For each region in the BED file\n",
    "        for _, region in bed.iterrows():\n",
    "            chrom = region['chrom']\n",
    "            start = region['start']\n",
    "            end = region['end']\n",
    "            print(f\"Simulating reads for {chrom}:{start}-{end}\")\n",
    "\n",
    "            # Initialize true coverage array for this chromosome if not already\n",
    "            if chrom not in true_coverage_arrays:\n",
    "                true_coverage_arrays[chrom] = np.zeros(fasta.get_reference_length(chrom), dtype=int)\n",
    "\n",
    "            # Generate read pairs overlapping the region\n",
    "            num_reads = random.randint(1, max_reads)  # Random number of read pairs\n",
    "            for _ in range(num_reads):\n",
    "                # Randomly select starting position for read1, allowing partial overlap with the BED region\n",
    "                read1_start = random.randint(max(0, start - read_len), min(end, fasta.get_reference_length(chrom) - read_len))\n",
    "                read2_start = read1_start + read_len + read_sep\n",
    "\n",
    "                # Fetch sequences\n",
    "                read1_seq = fasta.fetch(chrom, read1_start, read1_start + read_len)\n",
    "                read2_seq = fasta.fetch(chrom, read2_start, read2_start + read_len)\n",
    "\n",
    "                # Skip incomplete sequences\n",
    "                if len(read1_seq) < read_len or len(read2_seq) < read_len:\n",
    "                    continue\n",
    "\n",
    "                # Check if the read pair overlaps the region\n",
    "                read1_end = read1_start + read_len\n",
    "                read2_end = read2_start + read_len\n",
    "                if (read1_start < end and read1_end > start) or (read2_start < end and read2_end > start):\n",
    "                    \n",
    "                    # Update true coverage for read1\n",
    "                    true_coverage_arrays[chrom][read1_start:read1_start + read_len] += 1\n",
    "\n",
    "                    # Update true coverage for read2\n",
    "                    true_coverage_arrays[chrom][read2_start:read2_start + read_len] += 1\n",
    "\n",
    "                    # Create read1\n",
    "                    read1 = pysam.AlignedSegment()\n",
    "                    read1.query_name = f\"read_{chrom}_{read1_start}_{read1_start + read_len}\"\n",
    "                    read1.query_sequence = read1_seq\n",
    "                    read1.flag = 99\n",
    "                    read1.reference_id = bamfile.get_tid(chrom)\n",
    "                    read1.reference_start = read1_start\n",
    "                    read1.mapping_quality = 60\n",
    "                    read1.cigar = [(0, len(read1_seq))]\n",
    "                    read1.next_reference_id = bamfile.get_tid(chrom)\n",
    "                    read1.next_reference_start = read2_start\n",
    "                    read1.template_length = read2_start + read_len - read1_start\n",
    "                    read1.query_qualities = pysam.qualitystring_to_array(\"I\" * len(read1_seq))\n",
    "\n",
    "                    # Create read2\n",
    "                    read2 = pysam.AlignedSegment()\n",
    "                    read2.query_name = read1.query_name\n",
    "                    read2.query_sequence = read2_seq\n",
    "                    read2.flag = 147\n",
    "                    read2.reference_id = bamfile.get_tid(chrom)\n",
    "                    read2.reference_start = read2_start\n",
    "                    read2.mapping_quality = 60\n",
    "                    read2.cigar = [(0, len(read2_seq))]\n",
    "                    read2.next_reference_id = bamfile.get_tid(chrom)\n",
    "                    read2.next_reference_start = read1_start\n",
    "                    read2.template_length = -(read2_start + read_len - read1_start)\n",
    "                    read2.query_qualities = pysam.qualitystring_to_array(\"I\" * len(read2_seq))\n",
    "\n",
    "                    # Write reads to BAM file\n",
    "                    bamfile.write(read1)\n",
    "                    bamfile.write(read2)\n",
    "\n",
    "    # Sort the BAM file\n",
    "    pysam.sort(\"-o\", str(inbam), str(inbam))\n",
    "\n",
    "    # Index the BAM file\n",
    "    pysam.index(str(inbam))\n",
    "\n",
    "    # Extract coverage arrays for each BED region\n",
    "    coverage_by_region = {}\n",
    "    for _, region in bed.iterrows():\n",
    "        chrom, start, end = region['chrom'], region['start'], region['end']\n",
    "        coverage_by_region[f\"{chrom}:{start}-{end}\"] = true_coverage_arrays[chrom][start:end]\n",
    "\n",
    "    return coverage_by_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating reads for chr1:4-28\n",
      "Simulating reads for chr1:47-76\n",
      "Simulating reads for chr2:46-72\n",
      "Simulating reads for chr2:174-197\n",
      "Simulating reads for chr3:18-43\n",
      "Simulating reads for chr3:78-106\n",
      "Simulating reads for chr4:35-60\n",
      "Simulating reads for chr4:87-111\n",
      "Simulating reads for chr5:40-62\n",
      "Simulating reads for chr5:156-181\n",
      "Simulating reads for chr6:19-49\n",
      "Simulating reads for chr6:61-85\n",
      "Simulating reads for chr7:12-34\n",
      "Simulating reads for chr7:153-174\n",
      "Simulating reads for chr1:4-28\n",
      "Simulating reads for chr1:47-76\n",
      "Simulating reads for chr2:46-72\n",
      "Simulating reads for chr2:174-197\n",
      "Simulating reads for chr3:18-43\n",
      "Simulating reads for chr3:78-106\n",
      "Simulating reads for chr4:35-60\n",
      "Simulating reads for chr4:87-111\n",
      "Simulating reads for chr5:40-62\n",
      "Simulating reads for chr5:156-181\n",
      "Simulating reads for chr6:19-49\n",
      "Simulating reads for chr6:61-85\n",
      "Simulating reads for chr7:12-34\n",
      "Simulating reads for chr7:153-174\n",
      "Simulating reads for chr1:4-28\n",
      "Simulating reads for chr1:47-76\n",
      "Simulating reads for chr2:46-72\n",
      "Simulating reads for chr2:174-197\n",
      "Simulating reads for chr3:18-43\n",
      "Simulating reads for chr3:78-106\n",
      "Simulating reads for chr4:35-60\n",
      "Simulating reads for chr4:87-111\n",
      "Simulating reads for chr5:40-62\n",
      "Simulating reads for chr5:156-181\n",
      "Simulating reads for chr6:19-49\n",
      "Simulating reads for chr6:61-85\n",
      "Simulating reads for chr7:12-34\n",
      "Simulating reads for chr7:153-174\n",
      "Simulating reads for chr1:4-28\n",
      "Simulating reads for chr1:47-76\n",
      "Simulating reads for chr2:46-72\n",
      "Simulating reads for chr2:174-197\n",
      "Simulating reads for chr3:18-43\n",
      "Simulating reads for chr3:78-106\n",
      "Simulating reads for chr4:35-60\n",
      "Simulating reads for chr4:87-111\n",
      "Simulating reads for chr5:40-62\n",
      "Simulating reads for chr5:156-181\n",
      "Simulating reads for chr6:19-49\n",
      "Simulating reads for chr6:61-85\n",
      "Simulating reads for chr7:12-34\n",
      "Simulating reads for chr7:153-174\n",
      "Simulating reads for chr1:4-28\n",
      "Simulating reads for chr1:47-76\n",
      "Simulating reads for chr2:46-72\n",
      "Simulating reads for chr2:174-197\n",
      "Simulating reads for chr3:18-43\n",
      "Simulating reads for chr3:78-106\n",
      "Simulating reads for chr4:35-60\n",
      "Simulating reads for chr4:87-111\n",
      "Simulating reads for chr5:40-62\n",
      "Simulating reads for chr5:156-181\n",
      "Simulating reads for chr6:19-49\n",
      "Simulating reads for chr6:61-85\n",
      "Simulating reads for chr7:12-34\n",
      "Simulating reads for chr7:153-174\n"
     ]
    }
   ],
   "source": [
    "# Make 5 bam files called simulated1.bam, simulated2.bam, ..., simulated5.bam\n",
    "coverages = {}\n",
    "for i in range(1, 6):\n",
    "    coverage = simulate_bam(infasta, inbed, data_dir / f'simulated{i}.bam', seed=i)\n",
    "    coverages[f'simulated{i}.bam'] = coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save coverages in pickle file\n",
    "with open(data_dir / 'variable.bedcov.pkl', 'wb') as f:\n",
    "    pickle.dump(coverages, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `BigWig`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('chr1', 120),\n",
       " ('chr2', 400),\n",
       " ('chr3', 110),\n",
       " ('chr4', 150),\n",
       " ('chr5', 300),\n",
       " ('chr6', 100),\n",
       " ('chr7', 200)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make chromsizes a list of tuples\n",
    "chromsizes = []\n",
    "with open(data_dir / 'variable.chrom.sizes') as f:\n",
    "    for line in f:\n",
    "        chrom, size = line.strip().split()\n",
    "        chromsizes.append((chrom, int(size)))\n",
    "chromsizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/simulated1.bw\n",
      "chr1:4-28\n",
      "chr1:47-76\n",
      "chr2:46-72\n",
      "chr2:174-197\n",
      "chr3:18-43\n",
      "chr3:78-106\n",
      "chr4:35-60\n",
      "chr4:87-111\n",
      "chr5:40-62\n",
      "chr5:156-181\n",
      "chr6:19-49\n",
      "chr6:61-85\n",
      "chr7:12-34\n",
      "chr7:153-174\n",
      "/cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/simulated2.bw\n",
      "chr1:4-28\n",
      "chr1:47-76\n",
      "chr2:46-72\n",
      "chr2:174-197\n",
      "chr3:18-43\n",
      "chr3:78-106\n",
      "chr4:35-60\n",
      "chr4:87-111\n",
      "chr5:40-62\n",
      "chr5:156-181\n",
      "chr6:19-49\n",
      "chr6:61-85\n",
      "chr7:12-34\n",
      "chr7:153-174\n",
      "/cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/simulated3.bw\n",
      "chr1:4-28\n",
      "chr1:47-76\n",
      "chr2:46-72\n",
      "chr2:174-197\n",
      "chr3:18-43\n",
      "chr3:78-106\n",
      "chr4:35-60\n",
      "chr4:87-111\n",
      "chr5:40-62\n",
      "chr5:156-181\n",
      "chr6:19-49\n",
      "chr6:61-85\n",
      "chr7:12-34\n",
      "chr7:153-174\n",
      "/cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/simulated4.bw\n",
      "chr1:4-28\n",
      "chr1:47-76\n",
      "chr2:46-72\n",
      "chr2:174-197\n",
      "chr3:18-43\n",
      "chr3:78-106\n",
      "chr4:35-60\n",
      "chr4:87-111\n",
      "chr5:40-62\n",
      "chr5:156-181\n",
      "chr6:19-49\n",
      "chr6:61-85\n",
      "chr7:12-34\n",
      "chr7:153-174\n",
      "/cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/simulated5.bw\n",
      "chr1:4-28\n",
      "chr1:47-76\n",
      "chr2:46-72\n",
      "chr2:174-197\n",
      "chr3:18-43\n",
      "chr3:78-106\n",
      "chr4:35-60\n",
      "chr4:87-111\n",
      "chr5:40-62\n",
      "chr5:156-181\n",
      "chr6:19-49\n",
      "chr6:61-85\n",
      "chr7:12-34\n",
      "chr7:153-174\n"
     ]
    }
   ],
   "source": [
    "# Create a bigwig file from the coverage arrays\n",
    "for bam, coverage in coverages.items():\n",
    "    outbw = Path(data_dir / bam.replace('.bam', '.bw'))\n",
    "    regions = sorted(coverage.keys(), key=lambda x: (x.split(':')[0], int(x.split(':')[1].split('-')[0])))\n",
    "    bw = pyBigWig.open(str(outbw), 'w')\n",
    "    bw.addHeader(chromsizes, maxZooms=0)\n",
    "    print(outbw)\n",
    "    for region in regions:\n",
    "        print(region)\n",
    "        cov = coverage[region]\n",
    "        chrom, interval = region.split(':')\n",
    "        starts = np.arange(int(interval.split('-')[0]), int(interval.split('-')[1])).tolist()\n",
    "        bw.addEntries(chrom, starts, values=cov.astype(\"float32\").tolist(), span=1)\n",
    "    bw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'version': 4, 'nLevels': 0, 'nBasesCovered': 348, 'minVal': 0, 'maxVal': 7, 'sumData': 904, 'sumSquared': 3438}\n"
     ]
    }
   ],
   "source": [
    "# Test opening the bigwig file\n",
    "bw = pyBigWig.open(str(data_dir / 'simulated1.bw'))\n",
    "print(bw.header())\n",
    "bw.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `variable.tsv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable length sequences\n",
    "\n",
    "# Single scalar targets (sample from a normal distribution)\n",
    "targets = np.random.normal(size=(len(seqs), 1))\n",
    "\n",
    "# Save as a tsv file called variable.tsv\n",
    "df = pd.DataFrame({'seq': seqs, 'target': targets.flatten()})\n",
    "df.to_csv(data_dir / 'variable.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `fixed.tsv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the first 20bp of each sequence\n",
    "fixed_seqs = [seq[:20] for seq in seqs]\n",
    "\n",
    "# Save as a tsv file called fixed.tsv\n",
    "df = pd.DataFrame({'seq': fixed_seqs, 'target': targets.flatten()})\n",
    "df.to_csv(data_dir / 'fixed.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K562 ATAC-seq data chr22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsample_fasta_to_chr22(input_fasta, output_fasta, chromsizes_file):\n",
    "    \"\"\"\n",
    "    Subsamples a FASTA file to include only chr22 and writes the corresponding chromsizes file.\n",
    "    \n",
    "    Parameters:\n",
    "        input_fasta (str): Path to the input FASTA file.\n",
    "        output_fasta (str): Path to the output FASTA file containing only chr22.\n",
    "        chromsizes_file (str): Path to the output chromsizes file for chr22.\n",
    "    \"\"\"\n",
    "    with pysam.FastaFile(input_fasta) as fasta_in, open(output_fasta, 'w') as fasta_out, open(chromsizes_file, 'w') as chromsizes_out:\n",
    "        # Check if chr22 exists in the reference\n",
    "        if \"chr22\" not in fasta_in.references:\n",
    "            raise ValueError(\"chr22 not found in the input FASTA file.\")\n",
    "        \n",
    "        # Get chr22 sequence and write it to the output FASTA\n",
    "        chr22_sequence = fasta_in.fetch(\"chr22\")\n",
    "        chr22_length = fasta_in.get_reference_length(\"chr22\")\n",
    "        \n",
    "        fasta_out.write(f\">chr22\\n\")\n",
    "        for i in range(0, len(chr22_sequence), 80):  # Wrap sequence at 80 characters\n",
    "            fasta_out.write(chr22_sequence[i:i+80] + \"\\n\")\n",
    "        \n",
    "        # Write chr22 chromsize to the chromsizes file\n",
    "        chromsizes_out.write(f\"chr22\\t{chr22_length}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and output paths\n",
    "input_fasta = \"/cellar/users/aklie/data/datasets/SeqDatasets/K562_ATAC-seq/data/hg38.fa\"\n",
    "output_fasta = \"/cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/K562_ATAC-seq_chr22/hg38.chr22.fa\"\n",
    "chromsizes_file = \"/cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/K562_ATAC-seq_chr22/hg38.chr22.chromsizes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Caching the list of root modules, please wait!\n",
      "(This will only be done once - type '%rehashx' to reset cache!)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the subsampling function\n",
    "subsample_fasta_to_chr22(input_fasta, output_fasta, chromsizes_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_bed = \"/cellar/users/aklie/data/datasets/SeqDatasets/K562_ATAC-seq/data/ENCSR868FGK_K562_ATAC-seq_peaks.bed\"\n",
    "output_bed = \"/cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/K562_ATAC-seq_chr22/ENCSR868FGK.chr22.bed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsample the BED file to include only chr22\n",
    "with open(input_bed, 'r') as bed_in, open(output_bed, 'w') as bed_out:\n",
    "    for line in bed_in:\n",
    "        if line.startswith(\"chr22\"):\n",
    "            bed_out.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_bam = '/cellar/users/aklie/data/datasets/SeqDatasets/K562_ATAC-seq/data/merged.bam'\n",
    "output_bam = '/cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/K562_ATAC-seq_chr22/ENCSR868FGK.chr22.bam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsample bam file to include only chr22 using pysam\n",
    "def subsample_bam_to_chr22(input_bam, output_bam):\n",
    "    \"\"\"\n",
    "    Subsamples a BAM file to include only reads mapped to chr22.\n",
    "    \n",
    "    Parameters:\n",
    "        input_bam (str): Path to the input BAM file.\n",
    "        output_bam (str): Path to the output BAM file with only chr22 reads.\n",
    "    \"\"\"\n",
    "    # Open the input BAM file for reading\n",
    "    with pysam.AlignmentFile(input_bam, \"rb\") as bam_in:\n",
    "        # Open the output BAM file for writing\n",
    "        with pysam.AlignmentFile(output_bam, \"wb\", header=bam_in.header) as bam_out:\n",
    "            # Iterate over reads mapped to chr22 and write them to the output file\n",
    "            for read in bam_in.fetch(\"chr22\"):\n",
    "                bam_out.write(read)\n",
    "\n",
    "# Run the subsampling function\n",
    "subsample_bam_to_chr22(input_bam, output_bam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index the output bam file\n",
    "pysam.index(output_bam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%bash\n",
    "# use chrombpnet to get unstranded counts bigwig with correct shift (+4/-4)\n",
    "source activate chrombpnet\n",
    "script=/cellar/users/aklie/opt/chrombpnet/chrombpnet/helpers/preprocessing/reads_to_bigwig.py\n",
    "cmd=\"python $script \\\n",
    "--genome /cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/K562_ATAC-seq_chr22/hg38.chr22.fa \\\n",
    "--input-bam-file /cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/K562_ATAC-seq_chr22/ENCSR868FGK.chr22.bam \\\n",
    "--chrom-sizes /cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/K562_ATAC-seq_chr22/hg38.chr22.chromsizes \\\n",
    "--output-prefix /cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/K562_ATAC-seq_chr22/ENCSR868FGK.chr22 \\\n",
    "--data-type ATAC\"\n",
    "echo $cmd\n",
    "eval $cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%bash\n",
    "# use bam2bw to get bigwig\n",
    "#bam2bw [-h] -s SIZES -n NAME [-ps POS_SHIFT] [-ns NEG_SHIFT] [-v] filename [filename ...]\n",
    "cmd=\"bam2bw \\\n",
    "-s /cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/K562_ATAC-seq_chr22/hg38.chr22.chromsizes \\\n",
    "-n /cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/K562_ATAC-seq_chr22/ENCSR868FGK.chr22.bam2bw \\\n",
    "/cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/K562_ATAC-seq_chr22/ENCSR868FGK.chr22.bam\"\n",
    "echo $cmd\n",
    "eval $cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deBoer et al sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wget https://zenodo.org/records/10633252/files/filtered_test_data_with_MAUDE_expression.txt?download=1  -O /cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/yeast_promoters/filtered_test_data_with_MAUDE_expression.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add seq and exp columns as headers\n",
    "df = pd.read_csv('/cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/yeast_promoters/filtered_test_data_with_MAUDE_expression.txt', sep='\\t', header=None, names=['seq', 'exp'])\n",
    "df.to_csv('/cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/yeast_promoters/filtered_test_data_with_MAUDE_expression.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 eugene_tools",
   "language": "python",
   "name": "eugene_tools"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
