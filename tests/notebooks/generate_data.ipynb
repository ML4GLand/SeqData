{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Generate sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zarr\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from seqdata import Table, FlatFASTA, GenomeFASTA, BigWig, BAM\n",
    "import seqdata as sd\n",
    "import xarray as xr\n",
    "import pysam\n",
    "import random\n",
    "import pyBigWig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If seqpro is not installed, pip install it\n",
    "try:\n",
    "    import seqpro as sp\n",
    "except ImportError:\n",
    "    !pip install seqpro\n",
    "    import seqpro as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cellar/users/aklie/projects/ML4GLand/SeqData/tests/data\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path(sd.__file__).resolve().parent.parent / 'tests' / 'data'\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a numpy array of sequences to a FASTA file, if names is None, then the sequences are named chr1, chr2, etc.\n",
    "def write_fasta(arr, names=None, path='test.fasta', max_per_line=60):\n",
    "    if names is None:\n",
    "        names = [f'chr{i+1}' for i in range(arr.shape[0])]\n",
    "    with open(path, 'w') as f:\n",
    "        for name, seq in zip(names, arr):\n",
    "            f.write(f'>{name}\\n')\n",
    "            for i in range(0, len(seq), max_per_line):\n",
    "                f.write(seq[i:i+max_per_line] + '\\n')\n",
    "            f.write('\\n')\n",
    "    return path    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random 7 \"chromosomes\" (chr1, chr2, ..., chr7) of variable lengths\n",
    "seq_lens = [120, 400, 110, 150, 300, 100, 200]\n",
    "seqs = [''.join(sp.random_seqs((1, l), sp.DNA)[0].astype(str)) for l in seq_lens]\n",
    "names = [f'chr{i+1}' for i in range(7)]\n",
    "seq_dict = {name: seq for name, seq in zip(names, seqs)}\n",
    "\n",
    "# For chr2, make 50 random basepairs lower case\n",
    "indexes = np.random.choice(range(len(seqs[1])), 50)\n",
    "seqs[1] = ''.join([seqs[1][i].lower() if i in indexes else seqs[1][i] for i in range(len(seqs[1]))])\n",
    "\n",
    "# For chr 6, make random basepairs N\n",
    "#indexes = np.random.choice(range(len(seqs[5])), 80)\n",
    "#seqs[5] = ''.join(['N' if i in indexes else seqs[5][i] for i in range(len(seqs[5]))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fastas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `variable.fa`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as a fasta file called variable.fa\n",
    "write_fasta(seqs, names=names, path=data_dir / 'variable.fa')\n",
    "\n",
    "# Index it with pysam\n",
    "pysam.faidx(str(Path(data_dir) / 'variable.fa'))\n",
    "\n",
    "# Write variable.chrom.sizes\n",
    "with open(data_dir / 'variable.chrom.sizes', 'w') as f:\n",
    "    for i, l in enumerate(seq_lens):\n",
    "        f.write(f'chr{i+1}\\t{l}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `fixed.fa`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the first 80bp of each sequence\n",
    "fixed_seqs = [seq[:80] for seq in seqs]\n",
    "\n",
    "# Save as a fasta file called fixed.fa\n",
    "write_fasta(fixed_seqs, names=names, path=data_dir / 'fixed.fa')\n",
    "\n",
    "# Index it with pysam\n",
    "pysam.faidx(str(Path(data_dir) / 'fixed.fa'))\n",
    "\n",
    "# Write fixed.chrom.sizes\n",
    "with open(data_dir / 'fixed.chrom.sizes', 'w') as f:\n",
    "    for i, l in enumerate(seq_lens):\n",
    "        f.write(f'chr{i+1}\\t{l}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BEDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `variable.bed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_regions(sequences, num_regions=2, min_len=20, max_len=30):\n",
    "    regions = []\n",
    "    \n",
    "    for chrom, seq in sequences.items():\n",
    "        seq_len = len(seq)\n",
    "        selected_regions = []\n",
    "        \n",
    "        for _ in range(num_regions):\n",
    "            while True:\n",
    "                # Generate random length and start position\n",
    "                region_length = random.randint(min_len, max_len)\n",
    "                start = random.randint(0, seq_len - region_length)\n",
    "                end = start + region_length\n",
    "                \n",
    "                # Ensure no overlap with previous regions\n",
    "                if all(end <= r[1] or start >= r[2] for r in selected_regions):\n",
    "                    selected_regions.append((chrom, start, end))\n",
    "                    break\n",
    "        \n",
    "        regions.extend(selected_regions)\n",
    "    \n",
    "    return regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 2 random intervals on each chromosome from variable.fa using start and end coordinates\n",
    "regions = generate_regions(seq_dict)\n",
    "\n",
    "# Save as a tsv file called variable.bed with no header\n",
    "df = pd.DataFrame({'chrom': [r[0] for r in regions], 'start': [r[1] for r in regions], 'end': [r[2] for r in regions]})\n",
    "df.sort_values(['chrom', 'start']).to_csv(data_dir / 'variable.bed', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `fixed.bed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as a tsv file called fixed.bed with no header\n",
    "fixed_df = pd.DataFrame({'chrom': df['chrom'], 'start': df['start'], 'end': df['start'] + 20})\n",
    "fixed_df.sort_values(['chrom', 'start']).to_csv(data_dir / 'fixed.bed', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BAMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/variable.fa'),\n",
       " PosixPath('/cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/variable.bed'))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get file name\n",
    "infasta = Path(sd.__file__).resolve().parent.parent / 'tests' / 'data' / 'variable.fa'\n",
    "inbed = Path(sd.__file__).resolve().parent.parent / 'tests' / 'data' / 'variable.bed'\n",
    "infasta, inbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_bam(\n",
    "    infasta: Path,\n",
    "    inbed: Path,\n",
    "    inbam: Path,\n",
    "    read_len: int = 10,\n",
    "    read_sep: int = 5,\n",
    "    max_reads: int = 10,\n",
    "    seed: int = 0,\n",
    "):\n",
    "    # Open your reference FASTA file\n",
    "    fasta = pysam.FastaFile(infasta)\n",
    "    bed = pd.read_csv(inbed, sep='\\t', header=None, names=['chrom', 'start', 'end'])\n",
    "\n",
    "    # Parameters\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Dictionary to store true coverage for each chromosome\n",
    "    true_coverage_arrays = {}\n",
    "\n",
    "    # Open BAM file for writing\n",
    "    with pysam.AlignmentFile(inbam, 'wb',\n",
    "                             reference_names=fasta.references,\n",
    "                             reference_lengths=fasta.lengths) as bamfile:\n",
    "        # For each region in the BED file\n",
    "        for _, region in bed.iterrows():\n",
    "            chrom = region['chrom']\n",
    "            start = region['start']\n",
    "            end = region['end']\n",
    "            print(f\"Simulating reads for {chrom}:{start}-{end}\")\n",
    "\n",
    "            # Initialize true coverage array for this chromosome if not already\n",
    "            if chrom not in true_coverage_arrays:\n",
    "                true_coverage_arrays[chrom] = np.zeros(fasta.get_reference_length(chrom), dtype=int)\n",
    "\n",
    "            # Generate read pairs overlapping the region\n",
    "            num_reads = random.randint(1, max_reads)  # Random number of read pairs\n",
    "            for _ in range(num_reads):\n",
    "                # Randomly select starting position for read1, allowing partial overlap with the BED region\n",
    "                read1_start = random.randint(max(0, start - read_len), min(end, fasta.get_reference_length(chrom) - read_len))\n",
    "                read2_start = read1_start + read_len + read_sep\n",
    "\n",
    "                # Fetch sequences\n",
    "                read1_seq = fasta.fetch(chrom, read1_start, read1_start + read_len)\n",
    "                read2_seq = fasta.fetch(chrom, read2_start, read2_start + read_len)\n",
    "\n",
    "                # Skip incomplete sequences\n",
    "                if len(read1_seq) < read_len or len(read2_seq) < read_len:\n",
    "                    continue\n",
    "\n",
    "                # Check if the read pair overlaps the region\n",
    "                read1_end = read1_start + read_len\n",
    "                read2_end = read2_start + read_len\n",
    "                if (read1_start < end and read1_end > start) or (read2_start < end and read2_end > start):\n",
    "                    \n",
    "                    # Update true coverage for read1\n",
    "                    true_coverage_arrays[chrom][read1_start:read1_start + read_len] += 1\n",
    "\n",
    "                    # Update true coverage for read2\n",
    "                    true_coverage_arrays[chrom][read2_start:read2_start + read_len] += 1\n",
    "\n",
    "                    # Create read1\n",
    "                    read1 = pysam.AlignedSegment()\n",
    "                    read1.query_name = f\"read_{chrom}_{read1_start}_{read1_start + read_len}\"\n",
    "                    read1.query_sequence = read1_seq\n",
    "                    read1.flag = 99\n",
    "                    read1.reference_id = bamfile.get_tid(chrom)\n",
    "                    read1.reference_start = read1_start\n",
    "                    read1.mapping_quality = 60\n",
    "                    read1.cigar = [(0, len(read1_seq))]\n",
    "                    read1.next_reference_id = bamfile.get_tid(chrom)\n",
    "                    read1.next_reference_start = read2_start\n",
    "                    read1.template_length = read2_start + read_len - read1_start\n",
    "                    read1.query_qualities = pysam.qualitystring_to_array(\"I\" * len(read1_seq))\n",
    "\n",
    "                    # Create read2\n",
    "                    read2 = pysam.AlignedSegment()\n",
    "                    read2.query_name = read1.query_name\n",
    "                    read2.query_sequence = read2_seq\n",
    "                    read2.flag = 147\n",
    "                    read2.reference_id = bamfile.get_tid(chrom)\n",
    "                    read2.reference_start = read2_start\n",
    "                    read2.mapping_quality = 60\n",
    "                    read2.cigar = [(0, len(read2_seq))]\n",
    "                    read2.next_reference_id = bamfile.get_tid(chrom)\n",
    "                    read2.next_reference_start = read1_start\n",
    "                    read2.template_length = -(read2_start + read_len - read1_start)\n",
    "                    read2.query_qualities = pysam.qualitystring_to_array(\"I\" * len(read2_seq))\n",
    "\n",
    "                    # Write reads to BAM file\n",
    "                    bamfile.write(read1)\n",
    "                    bamfile.write(read2)\n",
    "\n",
    "    # Sort the BAM file\n",
    "    pysam.sort(\"-o\", str(inbam), str(inbam))\n",
    "\n",
    "    # Index the BAM file\n",
    "    pysam.index(str(inbam))\n",
    "\n",
    "    # Extract coverage arrays for each BED region\n",
    "    coverage_by_region = {}\n",
    "    for _, region in bed.iterrows():\n",
    "        chrom, start, end = region['chrom'], region['start'], region['end']\n",
    "        coverage_by_region[f\"{chrom}:{start}-{end}\"] = true_coverage_arrays[chrom][start:end]\n",
    "\n",
    "    return coverage_by_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating reads for chr1:4-28\n",
      "Simulating reads for chr1:47-76\n",
      "Simulating reads for chr2:46-72\n",
      "Simulating reads for chr2:174-197\n",
      "Simulating reads for chr3:18-43\n",
      "Simulating reads for chr3:78-106\n",
      "Simulating reads for chr4:35-60\n",
      "Simulating reads for chr4:87-111\n",
      "Simulating reads for chr5:40-62\n",
      "Simulating reads for chr5:156-181\n",
      "Simulating reads for chr6:19-49\n",
      "Simulating reads for chr6:61-85\n",
      "Simulating reads for chr7:12-34\n",
      "Simulating reads for chr7:153-174\n",
      "Simulating reads for chr1:4-28\n",
      "Simulating reads for chr1:47-76\n",
      "Simulating reads for chr2:46-72\n",
      "Simulating reads for chr2:174-197\n",
      "Simulating reads for chr3:18-43\n",
      "Simulating reads for chr3:78-106\n",
      "Simulating reads for chr4:35-60\n",
      "Simulating reads for chr4:87-111\n",
      "Simulating reads for chr5:40-62\n",
      "Simulating reads for chr5:156-181\n",
      "Simulating reads for chr6:19-49\n",
      "Simulating reads for chr6:61-85\n",
      "Simulating reads for chr7:12-34\n",
      "Simulating reads for chr7:153-174\n",
      "Simulating reads for chr1:4-28\n",
      "Simulating reads for chr1:47-76\n",
      "Simulating reads for chr2:46-72\n",
      "Simulating reads for chr2:174-197\n",
      "Simulating reads for chr3:18-43\n",
      "Simulating reads for chr3:78-106\n",
      "Simulating reads for chr4:35-60\n",
      "Simulating reads for chr4:87-111\n",
      "Simulating reads for chr5:40-62\n",
      "Simulating reads for chr5:156-181\n",
      "Simulating reads for chr6:19-49\n",
      "Simulating reads for chr6:61-85\n",
      "Simulating reads for chr7:12-34\n",
      "Simulating reads for chr7:153-174\n",
      "Simulating reads for chr1:4-28\n",
      "Simulating reads for chr1:47-76\n",
      "Simulating reads for chr2:46-72\n",
      "Simulating reads for chr2:174-197\n",
      "Simulating reads for chr3:18-43\n",
      "Simulating reads for chr3:78-106\n",
      "Simulating reads for chr4:35-60\n",
      "Simulating reads for chr4:87-111\n",
      "Simulating reads for chr5:40-62\n",
      "Simulating reads for chr5:156-181\n",
      "Simulating reads for chr6:19-49\n",
      "Simulating reads for chr6:61-85\n",
      "Simulating reads for chr7:12-34\n",
      "Simulating reads for chr7:153-174\n",
      "Simulating reads for chr1:4-28\n",
      "Simulating reads for chr1:47-76\n",
      "Simulating reads for chr2:46-72\n",
      "Simulating reads for chr2:174-197\n",
      "Simulating reads for chr3:18-43\n",
      "Simulating reads for chr3:78-106\n",
      "Simulating reads for chr4:35-60\n",
      "Simulating reads for chr4:87-111\n",
      "Simulating reads for chr5:40-62\n",
      "Simulating reads for chr5:156-181\n",
      "Simulating reads for chr6:19-49\n",
      "Simulating reads for chr6:61-85\n",
      "Simulating reads for chr7:12-34\n",
      "Simulating reads for chr7:153-174\n"
     ]
    }
   ],
   "source": [
    "# Make 5 bam files called simulated1.bam, simulated2.bam, ..., simulated5.bam\n",
    "coverages = {}\n",
    "for i in range(1, 6):\n",
    "    coverage = simulate_bam(infasta, inbed, data_dir / f'simulated{i}.bam', seed=i)\n",
    "    coverages[f'simulated{i}.bam'] = coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save coverages in pickle file\n",
    "with open(data_dir / 'variable.bedcov.pkl', 'wb') as f:\n",
    "    pickle.dump(coverages, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `BigWig`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('chr1', 120),\n",
       " ('chr2', 400),\n",
       " ('chr3', 110),\n",
       " ('chr4', 150),\n",
       " ('chr5', 300),\n",
       " ('chr6', 100),\n",
       " ('chr7', 200)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make chromsizes a list of tuples\n",
    "chromsizes = []\n",
    "with open(data_dir / 'variable.chrom.sizes') as f:\n",
    "    for line in f:\n",
    "        chrom, size = line.strip().split()\n",
    "        chromsizes.append((chrom, int(size)))\n",
    "chromsizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/simulated1.bw\n",
      "chr1:4-28\n",
      "chr1:47-76\n",
      "chr2:46-72\n",
      "chr2:174-197\n",
      "chr3:18-43\n",
      "chr3:78-106\n",
      "chr4:35-60\n",
      "chr4:87-111\n",
      "chr5:40-62\n",
      "chr5:156-181\n",
      "chr6:19-49\n",
      "chr6:61-85\n",
      "chr7:12-34\n",
      "chr7:153-174\n",
      "/cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/simulated2.bw\n",
      "chr1:4-28\n",
      "chr1:47-76\n",
      "chr2:46-72\n",
      "chr2:174-197\n",
      "chr3:18-43\n",
      "chr3:78-106\n",
      "chr4:35-60\n",
      "chr4:87-111\n",
      "chr5:40-62\n",
      "chr5:156-181\n",
      "chr6:19-49\n",
      "chr6:61-85\n",
      "chr7:12-34\n",
      "chr7:153-174\n",
      "/cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/simulated3.bw\n",
      "chr1:4-28\n",
      "chr1:47-76\n",
      "chr2:46-72\n",
      "chr2:174-197\n",
      "chr3:18-43\n",
      "chr3:78-106\n",
      "chr4:35-60\n",
      "chr4:87-111\n",
      "chr5:40-62\n",
      "chr5:156-181\n",
      "chr6:19-49\n",
      "chr6:61-85\n",
      "chr7:12-34\n",
      "chr7:153-174\n",
      "/cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/simulated4.bw\n",
      "chr1:4-28\n",
      "chr1:47-76\n",
      "chr2:46-72\n",
      "chr2:174-197\n",
      "chr3:18-43\n",
      "chr3:78-106\n",
      "chr4:35-60\n",
      "chr4:87-111\n",
      "chr5:40-62\n",
      "chr5:156-181\n",
      "chr6:19-49\n",
      "chr6:61-85\n",
      "chr7:12-34\n",
      "chr7:153-174\n",
      "/cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/simulated5.bw\n",
      "chr1:4-28\n",
      "chr1:47-76\n",
      "chr2:46-72\n",
      "chr2:174-197\n",
      "chr3:18-43\n",
      "chr3:78-106\n",
      "chr4:35-60\n",
      "chr4:87-111\n",
      "chr5:40-62\n",
      "chr5:156-181\n",
      "chr6:19-49\n",
      "chr6:61-85\n",
      "chr7:12-34\n",
      "chr7:153-174\n"
     ]
    }
   ],
   "source": [
    "# Create a bigwig file from the coverage arrays\n",
    "for bam, coverage in coverages.items():\n",
    "    outbw = Path(data_dir / bam.replace('.bam', '.bw'))\n",
    "    regions = sorted(coverage.keys(), key=lambda x: (x.split(':')[0], int(x.split(':')[1].split('-')[0])))\n",
    "    bw = pyBigWig.open(str(outbw), 'w')\n",
    "    bw.addHeader(chromsizes, maxZooms=0)\n",
    "    print(outbw)\n",
    "    for region in regions:\n",
    "        print(region)\n",
    "        cov = coverage[region]\n",
    "        chrom, interval = region.split(':')\n",
    "        starts = np.arange(int(interval.split('-')[0]), int(interval.split('-')[1])).tolist()\n",
    "        bw.addEntries(chrom, starts, values=cov.astype(\"float32\").tolist(), span=1)\n",
    "    bw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'version': 4, 'nLevels': 0, 'nBasesCovered': 348, 'minVal': 0, 'maxVal': 7, 'sumData': 904, 'sumSquared': 3438}\n"
     ]
    }
   ],
   "source": [
    "# Test opening the bigwig file\n",
    "bw = pyBigWig.open(str(data_dir / 'simulated1.bw'))\n",
    "print(bw.header())\n",
    "bw.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `variable.tsv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable length sequences\n",
    "\n",
    "# Single scalar targets (sample from a normal distribution)\n",
    "targets = np.random.normal(size=(len(seqs), 1))\n",
    "\n",
    "# Save as a tsv file called variable.tsv\n",
    "df = pd.DataFrame({'seq': seqs, 'target': targets.flatten()})\n",
    "df.to_csv(data_dir / 'variable.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `fixed.tsv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the first 20bp of each sequence\n",
    "fixed_seqs = [seq[:20] for seq in seqs]\n",
    "\n",
    "# Save as a tsv file called fixed.tsv\n",
    "df = pd.DataFrame({'seq': fixed_seqs, 'target': targets.flatten()})\n",
    "df.to_csv(data_dir / 'fixed.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deBoer et al sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wget https://zenodo.org/records/10633252/files/filtered_test_data_with_MAUDE_expression.txt?download=1  -O /cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/yeast_promoters/filtered_test_data_with_MAUDE_expression.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add seq and exp columns as headers\n",
    "df = pd.read_csv('/cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/yeast_promoters/filtered_test_data_with_MAUDE_expression.txt', sep='\\t', header=None, names=['seq', 'exp'])\n",
    "df.to_csv('/cellar/users/aklie/projects/ML4GLand/SeqData/tests/data/yeast_promoters/filtered_test_data_with_MAUDE_expression.txt', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 eugene_tools",
   "language": "python",
   "name": "eugene_tools"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
